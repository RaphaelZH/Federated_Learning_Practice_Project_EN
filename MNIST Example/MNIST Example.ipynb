{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c31541a9",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Importation des bibliothèques](#toc1_)    \n",
    "  - [Importation des paquets ou modules de la bibliothèque OpenFL](#toc1_1_)    \n",
    "  - [Importation des paquets ou modules de la bibliothèque PyTorch](#toc1_2_)    \n",
    "  - [Importation d’autres paquets ou modules requis](#toc1_3_)    \n",
    "- [Entraînement de modèle de réseau CNN](#toc2_)    \n",
    "  - [Définition des chargeurs de données](#toc2_1_)    \n",
    "  - [Définition du modèle de réseau CNN](#toc2_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4b940",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Importation des bibliothèques](#toc0_)\n",
    "\n",
    "## <a id='toc1_1_'></a>[Importation des paquets ou modules de la bibliothèque OpenFL](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f63aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.experimental.workflow.interface import Aggregator, Collaborator, FLSpec\n",
    "from openfl.experimental.workflow.placement import aggregator, collaborator\n",
    "from openfl.experimental.workflow.runtime import LocalRuntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dae77fc",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Importation des paquets ou modules de la bibliothèque PyTorch](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b89c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cee2a1",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Importation d’autres paquets ou modules requis](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d76255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a9ac6",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Entraînement de modèle de réseau CNN](#toc0_)\n",
    "\n",
    "## <a id='toc2_1_'></a>[Définition des chargeurs de données](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ffab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "01. torchvision.transforms.Compose(transforms)\n",
    "    - Composes several transforms together.\n",
    "\n",
    "02. torchvision.transforms.Normalize(mean, std, inplace=False)\n",
    "    - Normalize a tensor image with mean and standard deviation.\n",
    "    - output[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "\"\"\"\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    \"/tmp/files/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            # Les valeurs ` 0.1307` et `0.3081` utilisées pour la transformation `Normalize()`\n",
    "            # ci-dessous sont la moyenne globale et l’écart-type de l’ensemble de données MNIST.\n",
    "            torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST(\n",
    "    \"/tmp/files/\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f9c8b5",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Définition du modèle de réseau CNN](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba3007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "03. torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1,\n",
    "        groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "    - Applies a 2D convolution over an input signal composed of several input planes.\n",
    "\n",
    "04. torch.nn.Dropout2d(p=0.5, inplace=False)\n",
    "    - Randomly zero out entire channels.\n",
    "    - Each channel will be zeroed out independently on every forward call with probability p using\n",
    "    samples from a Bernoulli distribution.\n",
    "\n",
    "05. torch.nn.functional.max_pool2d(input, kernel_size, stride=None, padding=0,\n",
    "    dilation=1, ceil_mode=False, return_indices=False)\n",
    "    - Applies a 2D max pooling over an input signal composed of several input planes.\n",
    "\n",
    "06. torch.nn.functional.dropout(input, p=0.5, training=True, inplace=False)\n",
    "    - During training, randomly zeroes some elements of the input tensor with probability p.\n",
    "    - Uses samples from a Bernoulli distribution.\n",
    "\n",
    "07. torch.nn.functional.log_softmax(input, dim=None, _stacklevel=3, dtype=None)\n",
    "    - Apply a softmax followed by a logarithm.\n",
    "    - While mathematically equivalent to log(softmax(x)), doing these two operations separately is\n",
    "    slower and numerically unstable. This function uses an alternative formulation to compute the\n",
    "    output and gradient correctly.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # La première couche convolutionnelle : le nombre de canaux d’entrée est de 1, c’est-à-dire\n",
    "        # une image en niveaux de gris, le nombre de canaux de sortie est de 10, la taille du filtre\n",
    "        # convolutif est de 5x5, le stride est de 1 et le padding est de 0.\n",
    "\n",
    "        # Par conséquent, après que l'image d'entrée (1x28x28) a été convoluée, la taille de la\n",
    "        # carte de caractéristiques de sortie est de 10x24x24.\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        # La deuxième couche convolutionnelle : le nombre de canaux d’entrée est de 10, le nombre de\n",
    "        # canaux de sortie est de 20, la taille du filtre convolutif est de 5x5, le stride est de 1\n",
    "        # et le padding est de 0.\n",
    "\n",
    "        # Par conséquent, après que l'image d'entrée (10x12x12) a été convoluée, la taille de la\n",
    "        # carte de caractéristiques de sortie est de 20x8x8.\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        # Une couche d'abandon.\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        # La première couche de fully connected : le nombre de canaux d’entrée est de 20, chaque\n",
    "        # canal a une taille de 4x4, soit un total de 20x4x4 = 320 nœuds, tandis que la sortie est\n",
    "        # fixée à 50 nœuds.\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        # La deuxième couche de fully connected : l'entrée a 50 nœuds et la sortie a 10 nœuds \n",
    "        # (correspondant à 10 catégories).\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # La première couche convolutive est suivie d'une couche de pooling de type max pooling avec\n",
    "        # un filtre convolutif de taille de 2x2 et un stride égal à la longueur du filtre.\n",
    "\n",
    "        # La taille d'entrée est de 10x24x24, et après pooling, la taille de sortie est de 10x12x12.\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        # La deuxième couche convolutive est suivie d'une couche d'abandon.\n",
    "\n",
    "        # Après la couche d'abandon, suit une autre couche de max-pooling, qui possède un filtre\n",
    "        # convolutif de taille de 2x2 et un stride aussi égal à la longueur du filtre.\n",
    "\n",
    "        # La taille d'entrée est de 20x8x8, et après pooling, la taille de sortie est de 20x4x4.\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        # La carte de caractéristiques multidimensionnelle est transformée en un vecteur\n",
    "        # unidimensionnel, d'une taille de 20x4x4 = 320.\n",
    "        x = x.view(-1, 320)\n",
    "        # La première couche de fully connected, activée par la fonction d'activation ReLU.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Pendant l'entraînement du modèle, certains nœuds de la sortie de la première couche de\n",
    "        # fully connected sont mis à zéro de manière aléatoire avec une probabilité p.\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # La deuxième couche de fully connected sert également de couche de sortie.\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b360d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d174c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e76422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84be6c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 24, 24]             260\n",
      "            Conv2d-2             [-1, 20, 8, 8]           5,020\n",
      "         Dropout2d-3             [-1, 20, 8, 8]               0\n",
      "            Linear-4                   [-1, 50]          16,050\n",
      "            Linear-5                   [-1, 10]             510\n",
      "================================================================\n",
      "Total params: 21,840\n",
      "Trainable params: 21,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 0.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fcf125b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72aba2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.data[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12414797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  51, 159, 253, 159,  50,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          48, 238, 252, 252, 252, 237,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  54,\n",
       "         227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  60, 224,\n",
       "         252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 163, 252, 252,\n",
       "         252, 253, 252, 252,  96, 189, 253, 167,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 238, 253, 253,\n",
       "         190, 114, 253, 228,  47,  79, 255, 168,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252, 252, 179,\n",
       "          12,  75, 121,  21,   0,   0, 253, 243,  50,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  38, 165, 253, 233, 208,  84,\n",
       "           0,   0,   0,   0,   0,   0, 253, 252, 165,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,  28,\n",
       "           0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0, 255, 253, 196,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  76, 246, 252, 112,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0, 253, 252, 148,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  85, 252, 230,  25,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   7, 135, 253, 186,  12,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  85, 252, 223,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   7, 131, 252, 225,  71,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  85, 252, 145,   0,   0,   0,   0,   0,\n",
       "           0,   0,  48, 165, 252, 173,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,   0,\n",
       "           0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,  85, 178,\n",
       "         225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  85, 252, 252, 252, 229, 215, 252, 252,\n",
       "         252, 196, 130,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  28, 199, 252, 252, 253, 252, 252, 233,\n",
       "         145,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  25, 128, 252, 253, 252, 141,  37,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe98fd66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4c3ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
