{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45f58d2a",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Importation des bibliothèques](#toc1_)    \n",
    "  - [Importation des paquets ou modules de la bibliothèque OpenFL](#toc1_1_)    \n",
    "  - [Importation des paquets ou modules de la bibliothèque PyTorch](#toc1_2_)    \n",
    "  - [Importation d’autres paquets ou modules requis](#toc1_3_)    \n",
    "- [Définition du modèle d‘entraînement](#toc2_)    \n",
    "  - [Définition des chargeurs de données](#toc2_1_)    \n",
    "  - [Définition du modèle de réseau CNN](#toc2_2_)    \n",
    "  - [Définition de la fonction d'inférence utilisée dans le test](#toc2_3_)    \n",
    "- [Définition des règles de l'apprentissage fédéré](#toc3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f35dacf",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Importation des bibliothèques](#toc0_)\n",
    "\n",
    "## <a id='toc1_1_'></a>[Importation des paquets ou modules de la bibliothèque OpenFL](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f63aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.experimental.workflow.interface import Aggregator, Collaborator, FLSpec\n",
    "from openfl.experimental.workflow.placement import aggregator, collaborator\n",
    "from openfl.experimental.workflow.runtime import LocalRuntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdd759a",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Importation des paquets ou modules de la bibliothèque PyTorch](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b89c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c248ba8",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Importation d’autres paquets ou modules requis](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d76255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from termcolor import cprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4f0f5",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Définition du modèle d‘entraînement](#toc0_)\n",
    "\n",
    "## <a id='toc2_1_'></a>[Définition des chargeurs de données](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ffab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "01. torchvision.transforms.Compose(transforms)\n",
    "    - Composes several transforms together.\n",
    "\n",
    "02. torchvision.transforms.Normalize(mean, std, inplace=False)\n",
    "    - Normalize a tensor image with mean and standard deviation.\n",
    "    - output[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "\"\"\"\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    \"/tmp/files/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            # Les valeurs ` 0.1307` et `0.3081` utilisées pour la transformation `Normalize()`\n",
    "            # ci-dessous sont la moyenne globale et l’écart-type de l’ensemble de données MNIST.\n",
    "            torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST(\n",
    "    \"/tmp/files/\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b599d5",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Définition du modèle de réseau CNN](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba3007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "03. torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1,\n",
    "    groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "    - Applies a 2D convolution over an input signal composed of several input planes.\n",
    "\n",
    "04. torch.nn.Dropout2d(p=0.5, inplace=False)\n",
    "    - Randomly zero out entire channels.\n",
    "    - Each channel will be zeroed out independently on every forward call with probability p using\n",
    "    samples from a Bernoulli distribution.\n",
    "\n",
    "05. torch.nn.functional.max_pool2d(input, kernel_size, stride=None, padding=0,\n",
    "    dilation=1, ceil_mode=False, return_indices=False)\n",
    "    - Applies a 2D max pooling over an input signal composed of several input planes.\n",
    "\n",
    "06. torch.nn.functional.dropout(input, p=0.5, training=True, inplace=False)\n",
    "    - During training, randomly zeroes some elements of the input tensor with probability p.\n",
    "    - Uses samples from a Bernoulli distribution.\n",
    "\n",
    "07. torch.nn.functional.log_softmax(input, dim=None, _stacklevel=3, dtype=None)\n",
    "    - Apply a softmax followed by a logarithm.\n",
    "    - While mathematically equivalent to log(softmax(x)), doing these two operations separately is\n",
    "    slower and numerically unstable. This function uses an alternative formulation to compute the\n",
    "    output and gradient correctly.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # La première couche convolutionnelle : le nombre de canaux d’entrée est de 1, c’est-à-dire\n",
    "        # une image en niveaux de gris, le nombre de canaux de sortie est de 10, la taille du filtre\n",
    "        # convolutif est de 5x5, le stride est de 1 et le padding est de 0.\n",
    "\n",
    "        # Par conséquent, après que l'image d'entrée (1x28x28) a été convoluée, la taille de la\n",
    "        # carte de caractéristiques de sortie est de 10x24x24.\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        # La deuxième couche convolutionnelle : le nombre de canaux d’entrée est de 10, le nombre de\n",
    "        # canaux de sortie est de 20, la taille du filtre convolutif est de 5x5, le stride est de 1\n",
    "        # et le padding est de 0.\n",
    "\n",
    "        # Par conséquent, après que l'image d'entrée (10x12x12) a été convoluée, la taille de la\n",
    "        # carte de caractéristiques de sortie est de 20x8x8.\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        # Une couche d'abandon.\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        # La première couche de fully connected : le nombre de canaux d’entrée est de 20, chaque\n",
    "        # canal a une taille de 4x4, soit un total de 20x4x4 = 320 nœuds, tandis que la sortie est\n",
    "        # fixée à 50 nœuds.\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        # La deuxième couche de fully connected : l'entrée a 50 nœuds et la sortie a 10 nœuds\n",
    "        # (correspondant à 10 catégories).\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # La première couche convolutive est suivie d'une couche de pooling de type max pooling avec\n",
    "        # un filtre convolutif de taille de 2x2 et un stride égal à la longueur du filtre.\n",
    "\n",
    "        # La taille d'entrée est de 10x24x24, et après pooling, la taille de sortie est de 10x12x12.\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        # La deuxième couche convolutive est suivie d'une couche d'abandon.\n",
    "\n",
    "        # Après la couche d'abandon, suit une autre couche de max-pooling, qui possède un filtre\n",
    "        # convolutif de taille de 2x2 et un stride aussi égal à la longueur du filtre.\n",
    "\n",
    "        # La taille d'entrée est de 20x8x8, et après pooling, la taille de sortie est de 20x4x4.\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        # La carte de caractéristiques multidimensionnelle est transformée en un vecteur\n",
    "        # unidimensionnel, d'une taille de 20x4x4 = 320.\n",
    "        x = x.view(-1, 320)\n",
    "        # La première couche de fully connected, activée par la fonction d'activation ReLU.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Pendant l'entraînement du modèle, certains nœuds de la sortie de la première couche de\n",
    "        # fully connected sont mis à zéro de manière aléatoire avec une probabilité p.\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # La deuxième couche de fully connected sert également de couche de sortie.\n",
    "        x = self.fc2(x)\n",
    "        # Les probabilités logarithmiques de tous les nœuds de la couche de sortie sont calculées en\n",
    "        # appliquant une fonction softmax suivie d'un logarithme.\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01738796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 24, 24]             260\n",
      "            Conv2d-2             [-1, 20, 8, 8]           5,020\n",
      "         Dropout2d-3             [-1, 20, 8, 8]               0\n",
      "            Linear-4                   [-1, 50]          16,050\n",
      "            Linear-5                   [-1, 10]             510\n",
      "================================================================\n",
      "Total params: 21,840\n",
      "Trainable params: 21,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 0.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "summary(model, next(iter(mnist_train))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7933b052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m  conv1.weight .............................................. 250  \u001b[0m\n",
      "\u001b[35m  conv1.bias ................................................. 10  \u001b[0m\n",
      "\u001b[35m  conv2.weight ............................................. 5000  \u001b[0m\n",
      "\u001b[35m  conv2.bias ................................................. 20  \u001b[0m\n",
      "\u001b[35m  fc1.weight .............................................. 16000  \u001b[0m\n",
      "\u001b[35m  fc1.bias ................................................... 50  \u001b[0m\n",
      "\u001b[35m  fc2.weight ................................................ 500  \u001b[0m\n",
      "\u001b[35m  fc2.bias ................................................... 10  \u001b[0m\n",
      "\u001b[35m _________________________________________________________________ \u001b[0m\n",
      "\u001b[35m  total parameters ........................................ 21840  \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    length = 67\n",
    "    names = [n for (n, p) in model.named_parameters() if p.requires_grad]\n",
    "    name = \"total parameters\"\n",
    "    names.append(name)\n",
    "    max_length = max(map(len, names))\n",
    "    formatted_names = [f\"{f'  {n} ':.<{max_length + 3}}\" for n in names]\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    params.append(sum(params))\n",
    "    formatted_params = [f\"{f' {p}  ':.>{length - max_length - 3}}\" for p in params]\n",
    "\n",
    "    for n, p in zip(formatted_names[:-1], formatted_params[:-1]):\n",
    "        cprint((n + p), \"magenta\")\n",
    "    cprint(\" \" + \"_\" * (length - 2) + \" \", \"magenta\")\n",
    "    cprint(\n",
    "        (formatted_names[-1] + formatted_params[-1]),\n",
    "        \"magenta\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "\n",
    "    return names, params\n",
    "\n",
    "\n",
    "names, params = count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c7793",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[Définition de la fonction d'inférence utilisée dans le test](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13b360d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "08. torch.nn.functional.nll_loss(input, target, weight=None, size_average=None, ignore_index=-100,\n",
    "    reduce=None, reduction='mean')\n",
    "    - Compute the negative log likelihood loss.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def inference(network, test_loader):\n",
    "    # Mettre le module en mode évaluation.\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            # L'entropie est une mesure de l'incertitude, c'est-à-dire que, si un résultat est\n",
    "            # ertain, l'entropie est faible.\n",
    "\n",
    "            # La perte d'entropie croisée, ou perte logarithmique mesure les performances d'un\n",
    "            # modèle de classification dont le résultat est une valeur de probabilité comprise entre\n",
    "            # 0 et 1.\n",
    "\n",
    "            # La perte d'entropie croisée augmente à mesure que la probabilité prédite s'écarte de\n",
    "            # l'étiquette réelle.\n",
    "\n",
    "            # L’entropie croisée catégorielle sert au classement en plusieurs classes.\n",
    "\n",
    "            # Le log-vraisemblance négatif est également connu sous le nom d'entropie croisée\n",
    "            # catégorielle, car il s'agit en fait de deux interprétations différentes de la même\n",
    "            # formule.\n",
    "\n",
    "            # test_loss += F.cross_entropy(output, target, reduction=\"sum\").item()\n",
    "            test_loss += F.nll_loss(output, target, reduction=\"sum\").item()\n",
    "\n",
    "            # Si `keepdim` est `True`, le tenseur de sortie est de la même taille que celui\n",
    "            # d'entrée, sauf dans la (les) dimension(s) `dim` où il est de taille 1.\n",
    "            pred = output.data.max(dim=1, keepdim=True)[1]\n",
    "            # Calcul de l'égalité par éléments.\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    cprint(\n",
    "        \"Test set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\".format(\n",
    "            test_loss,\n",
    "            correct,\n",
    "            len(test_loader.dataset),\n",
    "            100.0 * correct / len(test_loader.dataset),\n",
    "        ),\n",
    "        \"magenta\",\n",
    "        attrs=[\"bold\"],\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "    accuracy = float(correct / len(test_loader.dataset))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f8c156a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[35mTest set: Avg. loss: 2.3048, Accuracy: 1261/10000 (13%)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12610000371932983"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(mnist_test, batch_size=500, shuffle=False)\n",
    "\n",
    "inference(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9556b2a",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Définition des règles de l'apprentissage fédéré](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59d93477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedAvg(models, weights=None):\n",
    "    new_model = models[0]\n",
    "    state_dicts = [model.state_dict() for model in models]\n",
    "    state_dict = new_model.state_dict()\n",
    "    for key in models[1].state_dict():\n",
    "        state_dict[key] = torch.from_numpy(\n",
    "            np.average(\n",
    "                [state[key].numpy() for state in state_dicts], axis=0, weights=weights\n",
    "            )\n",
    "        )\n",
    "    new_model.load_state_dict(state_dict)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "670a3019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[-0.0428, -0.1184,  0.0053, -0.0543,  0.0765],\n",
       "                        [ 0.1934,  0.1402,  0.0174,  0.0006,  0.0576],\n",
       "                        [-0.0954,  0.1654, -0.1308, -0.0902, -0.0322],\n",
       "                        [ 0.0194,  0.0912, -0.0360, -0.1713,  0.1123],\n",
       "                        [-0.0022,  0.1176, -0.1107,  0.0345,  0.0311]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0931,  0.1475,  0.0301, -0.0156,  0.1245],\n",
       "                        [-0.1344, -0.0358, -0.1426, -0.0455, -0.0130],\n",
       "                        [ 0.0679,  0.0929,  0.0991, -0.0485, -0.0330],\n",
       "                        [-0.1611,  0.1250,  0.0365,  0.0378, -0.1298],\n",
       "                        [ 0.1820, -0.1564, -0.1450, -0.1987,  0.0268]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0744,  0.0728, -0.1095,  0.1704,  0.0221],\n",
       "                        [-0.0366,  0.1959,  0.0875, -0.1827,  0.1334],\n",
       "                        [-0.1333,  0.1119,  0.0667, -0.0182, -0.1045],\n",
       "                        [-0.1701,  0.0815, -0.0581, -0.1911,  0.0060],\n",
       "                        [-0.1071, -0.1147,  0.0673, -0.0984,  0.1329]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1626, -0.1029, -0.1220, -0.1323,  0.1776],\n",
       "                        [-0.0685, -0.1608, -0.0336,  0.1947, -0.0922],\n",
       "                        [-0.1023,  0.1580,  0.1224,  0.0977, -0.1534],\n",
       "                        [-0.1149,  0.0224, -0.1052,  0.0244,  0.1526],\n",
       "                        [ 0.1598, -0.0435,  0.1018,  0.1303,  0.0418]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0137,  0.0853,  0.1009, -0.0780,  0.1999],\n",
       "                        [ 0.1351,  0.1296, -0.1309,  0.0384,  0.0269],\n",
       "                        [-0.0939, -0.0161,  0.1445,  0.0895,  0.0067],\n",
       "                        [ 0.0737, -0.1021,  0.1208,  0.0430,  0.0742],\n",
       "                        [-0.0993,  0.1107, -0.1364, -0.1229,  0.1612]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0081, -0.0824, -0.0972, -0.0748, -0.0985],\n",
       "                        [-0.1006,  0.0450, -0.0403, -0.0059,  0.0581],\n",
       "                        [ 0.0419,  0.1995, -0.1129,  0.0595,  0.1751],\n",
       "                        [ 0.1712, -0.1233, -0.1253, -0.1957,  0.1254],\n",
       "                        [ 0.0927, -0.1873,  0.0324,  0.1085, -0.1350]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1126, -0.1409, -0.0498,  0.1449,  0.1668],\n",
       "                        [ 0.0588,  0.1698, -0.0501,  0.1723,  0.0038],\n",
       "                        [ 0.0847,  0.0913,  0.1398,  0.1029, -0.1270],\n",
       "                        [-0.1796,  0.0112,  0.1426, -0.0526, -0.1668],\n",
       "                        [-0.0796, -0.1704,  0.1455,  0.0545,  0.1671]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0849, -0.1389,  0.1670, -0.1268, -0.1874],\n",
       "                        [ 0.0827,  0.0205, -0.1604, -0.1905, -0.1748],\n",
       "                        [ 0.1128, -0.1592,  0.0939, -0.1776, -0.1436],\n",
       "                        [-0.0577, -0.0708, -0.1919,  0.0673,  0.0583],\n",
       "                        [ 0.1745, -0.0592, -0.0791,  0.1665,  0.0272]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1553, -0.0999, -0.0008, -0.0071,  0.1923],\n",
       "                        [ 0.1543, -0.0529, -0.0715, -0.0205,  0.0194],\n",
       "                        [ 0.0838, -0.0649, -0.1339,  0.1828, -0.1183],\n",
       "                        [-0.0554, -0.0858, -0.0297,  0.1489, -0.0740],\n",
       "                        [ 0.0537,  0.1495, -0.1018, -0.0057,  0.0472]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0183, -0.0154,  0.1338, -0.1270,  0.1699],\n",
       "                        [ 0.0432,  0.0076, -0.1437, -0.1541,  0.1055],\n",
       "                        [ 0.1343,  0.0111, -0.0193, -0.1109, -0.1996],\n",
       "                        [-0.1748, -0.1558,  0.0133,  0.1260,  0.1349],\n",
       "                        [ 0.0753,  0.1713, -0.0048, -0.1415,  0.0272]]]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([ 0.0282, -0.0380,  0.0701, -0.0198, -0.1424, -0.1034, -0.0618, -0.1027,\n",
       "                      -0.1440,  0.1964])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[-3.5531e-02,  1.0297e-02,  4.7469e-02, -2.7780e-02,  5.5506e-02],\n",
       "                        [ 3.3863e-02, -3.9999e-03,  2.0105e-02, -2.5161e-02, -4.6081e-02],\n",
       "                        [ 5.0336e-02,  3.9896e-02,  1.8259e-02,  2.8068e-02, -2.2694e-02],\n",
       "                        [ 2.2183e-04, -2.7014e-02, -2.7171e-02, -3.2750e-02,  8.4450e-03],\n",
       "                        [-4.8254e-03,  2.9927e-02, -1.4738e-02,  9.6393e-04,  6.3138e-02]],\n",
       "              \n",
       "                       [[-4.3480e-03, -4.0013e-03,  2.1252e-02,  3.7256e-02, -3.3884e-02],\n",
       "                        [-4.4199e-02, -5.2942e-03,  7.1573e-03, -7.0242e-03, -2.2430e-02],\n",
       "                        [ 5.6935e-03, -5.0053e-02, -1.1763e-02, -1.6307e-02, -5.1137e-02],\n",
       "                        [ 2.7661e-02,  4.3971e-02,  1.0250e-02, -4.0877e-02,  5.4580e-02],\n",
       "                        [-1.4662e-03, -3.3201e-02, -5.6222e-02, -4.3742e-02, -2.4767e-02]],\n",
       "              \n",
       "                       [[-6.2787e-02,  3.9461e-02,  5.6421e-02, -3.9956e-02,  4.2726e-02],\n",
       "                        [ 2.5679e-02, -4.7064e-02, -6.2856e-02,  1.4359e-02, -1.2009e-02],\n",
       "                        [ 3.1029e-02, -5.4980e-02,  2.6422e-02,  5.1782e-02,  1.4379e-02],\n",
       "                        [ 2.5022e-02, -3.0406e-02, -6.1927e-02,  3.0236e-02, -1.3674e-02],\n",
       "                        [ 1.3080e-02, -3.8580e-02, -3.2091e-02, -3.6234e-02, -2.8842e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.1580e-02,  6.2897e-02,  4.2919e-02,  1.3113e-02, -1.7187e-02],\n",
       "                        [ 5.3388e-02,  2.2637e-02, -2.7912e-02,  3.5138e-02, -2.9115e-02],\n",
       "                        [-1.7925e-02, -1.3908e-02,  3.4526e-02,  4.5301e-02,  2.0355e-02],\n",
       "                        [ 3.8254e-02,  1.7139e-02,  2.7385e-02, -2.4254e-02,  3.0359e-02],\n",
       "                        [ 4.8553e-02,  2.1527e-02, -1.9136e-02,  1.9544e-02,  4.0145e-04]],\n",
       "              \n",
       "                       [[-2.3258e-02,  5.8315e-02, -1.5799e-03,  4.3454e-02, -6.6038e-03],\n",
       "                        [-4.9246e-03,  4.4138e-02, -1.7272e-02,  1.1812e-02,  3.5012e-03],\n",
       "                        [ 2.8245e-02,  1.1744e-02,  2.6621e-02,  3.9353e-03, -5.6463e-02],\n",
       "                        [ 6.5167e-03, -1.6973e-02,  5.6432e-02,  2.6071e-05,  4.5901e-02],\n",
       "                        [ 3.9493e-02,  1.6294e-02, -5.1186e-02,  6.1744e-02,  3.3252e-03]],\n",
       "              \n",
       "                       [[-1.7707e-02, -4.1046e-02, -6.3104e-02, -3.1144e-02,  1.4113e-02],\n",
       "                        [-4.9084e-02, -1.6189e-02, -3.2674e-02, -3.2765e-02, -5.6798e-02],\n",
       "                        [-3.2530e-02,  5.4594e-02, -3.4854e-02, -1.2874e-02,  4.1762e-02],\n",
       "                        [-5.9644e-02, -9.0159e-03, -2.7864e-02, -5.5983e-02, -1.5029e-02],\n",
       "                        [ 3.8624e-02,  4.9653e-02, -5.0016e-02,  3.1523e-02, -5.7900e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.3912e-02, -5.4952e-02,  3.3669e-02,  4.8957e-02, -6.1113e-02],\n",
       "                        [ 1.0839e-02,  5.6377e-02,  5.5042e-02, -6.2010e-02,  3.8260e-02],\n",
       "                        [-2.0841e-02,  2.5442e-02, -9.0565e-03,  6.0273e-02, -4.8462e-02],\n",
       "                        [ 2.4441e-02, -9.6088e-03,  1.9793e-02, -7.6699e-03, -1.9835e-02],\n",
       "                        [-5.8607e-02, -3.4678e-02,  1.5997e-02, -4.4880e-02, -3.5605e-02]],\n",
       "              \n",
       "                       [[ 5.3568e-02,  5.7885e-02,  2.3971e-02,  2.0732e-02,  4.1711e-02],\n",
       "                        [ 3.1069e-02,  5.6307e-02, -3.5655e-02, -4.3100e-02,  3.4493e-02],\n",
       "                        [ 2.6471e-02, -5.4168e-02,  7.7409e-03,  4.7304e-02,  6.2931e-04],\n",
       "                        [-2.5691e-02,  5.4297e-02, -1.2453e-02,  7.3156e-03, -5.2196e-02],\n",
       "                        [-3.2056e-02, -1.9861e-02, -1.1830e-02, -2.6316e-02, -3.0131e-02]],\n",
       "              \n",
       "                       [[-2.6987e-02,  4.0492e-02, -1.7747e-02, -3.6414e-02,  4.4248e-02],\n",
       "                        [ 5.1848e-02,  4.4579e-02, -3.1951e-04,  5.7215e-02, -2.5383e-02],\n",
       "                        [-2.7538e-02, -6.2865e-03,  1.5784e-02, -1.8061e-02, -2.0106e-03],\n",
       "                        [ 3.0015e-02,  3.1850e-02,  1.9744e-02,  5.4741e-02, -1.8831e-02],\n",
       "                        [ 2.4822e-02,  3.5071e-02,  5.5636e-02, -1.8368e-02, -3.2329e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.0529e-02, -6.4997e-03, -3.3264e-05, -4.6557e-03,  3.0697e-02],\n",
       "                        [ 3.9205e-02, -1.3557e-02, -1.4069e-02, -1.2053e-02, -4.1811e-02],\n",
       "                        [ 3.1485e-02, -2.8738e-02, -4.0197e-02,  2.7943e-02, -4.7420e-02],\n",
       "                        [-1.7943e-02, -5.9251e-02, -4.2528e-02,  1.7161e-02, -2.1996e-03],\n",
       "                        [-3.6429e-02, -1.9038e-02,  7.0024e-03, -2.1143e-02,  2.3999e-03]],\n",
       "              \n",
       "                       [[ 1.3301e-02, -2.6040e-02,  8.9533e-03,  1.8165e-03,  1.5425e-02],\n",
       "                        [ 4.8593e-02,  4.7567e-02, -5.6436e-02,  5.9974e-02,  2.5531e-02],\n",
       "                        [-6.1479e-02,  1.5803e-02,  2.6919e-03, -2.0528e-02, -2.3029e-02],\n",
       "                        [-3.4080e-02,  5.7799e-02, -3.9080e-02, -2.4434e-02,  1.0866e-02],\n",
       "                        [ 4.9294e-02, -4.3864e-02,  3.1791e-02, -3.6143e-02, -1.8381e-02]],\n",
       "              \n",
       "                       [[-1.1903e-02, -3.2325e-02, -5.0832e-02,  2.8071e-03, -5.0570e-02],\n",
       "                        [ 5.0238e-02, -4.9388e-02, -4.7691e-03,  5.7709e-02,  2.9207e-02],\n",
       "                        [-3.8365e-02,  1.2081e-02,  2.7343e-02, -6.1987e-02,  3.1137e-02],\n",
       "                        [ 4.3031e-03,  5.0269e-02,  3.6731e-02,  4.4526e-02,  4.5040e-02],\n",
       "                        [-6.1417e-02,  2.1628e-02,  1.5297e-02, -6.0811e-02,  2.3089e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1823e-02,  2.0729e-02, -5.9953e-02, -4.2598e-02,  2.4556e-02],\n",
       "                        [-6.0461e-02, -1.0405e-04, -7.2638e-03,  5.4277e-02, -8.7127e-03],\n",
       "                        [-1.5683e-03, -5.2017e-02,  1.1116e-02, -3.1020e-02, -4.2100e-02],\n",
       "                        [ 4.2801e-02, -5.4377e-02,  1.2198e-02, -2.2654e-02, -8.2355e-03],\n",
       "                        [ 7.6674e-03, -5.0276e-02, -3.5523e-02,  2.7153e-02, -5.7539e-02]],\n",
       "              \n",
       "                       [[-5.9019e-02,  3.5013e-02,  1.9910e-02,  5.9608e-03,  5.1692e-02],\n",
       "                        [ 2.9487e-02,  1.5220e-02,  6.0792e-02,  6.8936e-03, -2.6489e-02],\n",
       "                        [ 4.0499e-02,  1.6139e-03,  4.8648e-03, -1.2968e-02, -4.7702e-02],\n",
       "                        [ 5.1005e-02,  1.4709e-03,  1.1529e-02,  7.5312e-03,  1.2201e-02],\n",
       "                        [ 5.8351e-02,  4.0063e-02,  3.0104e-02, -3.3013e-02,  3.2369e-03]],\n",
       "              \n",
       "                       [[-3.5668e-02,  4.8955e-02, -3.4013e-02, -1.6164e-02,  3.3162e-02],\n",
       "                        [ 5.3850e-02,  3.7159e-02, -5.0406e-02,  6.3079e-02, -2.5721e-02],\n",
       "                        [-3.2543e-02, -4.4123e-03, -4.8487e-02,  2.6546e-02, -4.0846e-03],\n",
       "                        [-2.7931e-02,  4.3502e-02, -3.2632e-02, -5.6836e-02,  1.0229e-02],\n",
       "                        [ 2.3660e-02, -4.5688e-02, -1.2022e-02,  4.6286e-02,  4.6056e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.5474e-03, -7.4993e-03,  3.2958e-02, -1.9394e-02,  3.8488e-02],\n",
       "                        [ 4.7276e-03, -4.8423e-02, -2.9235e-02,  5.1636e-02, -2.3603e-02],\n",
       "                        [-5.0875e-02,  1.8371e-03, -4.3994e-02, -2.3314e-02,  3.3367e-02],\n",
       "                        [ 1.9724e-03, -3.5238e-02,  3.6159e-02, -1.9265e-02,  2.8256e-02],\n",
       "                        [ 7.1172e-03,  5.2694e-02, -3.3005e-02,  3.2963e-02, -1.7422e-02]],\n",
       "              \n",
       "                       [[-3.9163e-02,  4.9854e-02,  3.0193e-02, -4.1354e-02, -5.8651e-02],\n",
       "                        [ 5.3444e-02,  2.4365e-02,  3.2012e-02,  5.8876e-02, -3.8702e-02],\n",
       "                        [ 1.6478e-02, -4.0777e-02,  1.1185e-02,  9.9674e-03,  2.3905e-02],\n",
       "                        [ 4.5708e-02,  8.1636e-03,  5.0222e-02,  2.0131e-02,  2.9447e-02],\n",
       "                        [-1.8670e-02, -9.5286e-03, -4.0097e-02,  3.8444e-02,  2.5794e-02]],\n",
       "              \n",
       "                       [[-3.1605e-02, -3.8471e-02,  5.6324e-03,  1.6587e-02,  3.6200e-02],\n",
       "                        [-5.6954e-02,  4.6810e-02,  2.4260e-02,  2.8856e-02,  2.9510e-02],\n",
       "                        [ 2.9418e-02,  5.3989e-02, -2.4396e-02, -1.0680e-02, -5.1930e-02],\n",
       "                        [-1.6249e-02, -2.9695e-02,  3.4216e-04, -3.7997e-02,  3.9419e-02],\n",
       "                        [-1.7612e-05,  3.7304e-02, -2.1030e-02,  1.9347e-02,  3.6840e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 8.5655e-03,  5.5781e-02,  5.2321e-02,  3.4817e-02, -6.1597e-02],\n",
       "                        [-5.2975e-02,  6.1208e-02, -4.3427e-02, -1.3060e-02, -6.3195e-02],\n",
       "                        [-6.9587e-03, -1.7635e-02, -6.0476e-02, -3.7010e-02, -2.0741e-02],\n",
       "                        [-6.0610e-02,  2.9766e-02,  1.9408e-03,  6.8940e-03, -4.9784e-04],\n",
       "                        [-1.3074e-02, -1.9441e-03, -5.8548e-02, -1.5413e-02,  1.7666e-02]],\n",
       "              \n",
       "                       [[ 2.1293e-02, -1.2524e-03, -5.5766e-03, -4.4158e-02,  5.2761e-02],\n",
       "                        [ 3.8373e-02,  6.0796e-02, -1.4998e-02,  2.4041e-02,  8.1076e-03],\n",
       "                        [-1.6855e-02,  1.2311e-02,  3.5640e-02, -4.7131e-02, -4.0940e-02],\n",
       "                        [-5.6706e-02,  7.8630e-03, -5.9933e-02,  5.1359e-03,  1.5275e-03],\n",
       "                        [ 4.4657e-02, -1.8459e-03,  1.9352e-02, -4.3455e-03, -1.5699e-02]],\n",
       "              \n",
       "                       [[ 1.0469e-02,  4.3142e-02, -1.0033e-02, -3.1540e-02,  2.0086e-02],\n",
       "                        [-4.4121e-02,  2.6604e-02,  1.3492e-02, -5.4526e-02,  1.5810e-02],\n",
       "                        [-4.9559e-02,  1.5112e-02,  3.6543e-02, -3.9151e-02, -4.9327e-02],\n",
       "                        [-6.0921e-02,  6.0422e-02, -8.4908e-03,  3.9873e-02, -2.1664e-02],\n",
       "                        [-9.9102e-03,  5.4140e-02,  3.8706e-02,  3.5556e-02,  6.3162e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.5066e-02, -4.1705e-02, -9.1958e-03, -3.3568e-02,  3.6434e-02],\n",
       "                        [-2.4649e-02, -4.9057e-03, -6.0673e-02, -8.8258e-03, -1.4906e-02],\n",
       "                        [-4.4601e-03, -1.4910e-02,  4.2490e-02,  4.3568e-02,  4.7675e-02],\n",
       "                        [-5.1907e-02,  2.1849e-02,  1.7752e-02,  2.7700e-02,  7.4051e-03],\n",
       "                        [ 2.1438e-02,  7.6294e-03,  4.0459e-02,  4.9038e-02, -4.4580e-02]],\n",
       "              \n",
       "                       [[-5.4087e-02,  4.7347e-02, -2.0113e-02,  3.7181e-02, -4.4728e-02],\n",
       "                        [ 5.7980e-02,  1.4784e-02, -5.1838e-02, -1.2676e-03,  2.8871e-02],\n",
       "                        [ 4.8856e-03, -5.4758e-02, -3.1570e-02, -4.9529e-02, -1.2842e-02],\n",
       "                        [ 4.9164e-02, -3.2504e-02, -4.7054e-02, -6.1014e-02,  5.5222e-02],\n",
       "                        [ 5.6534e-03,  1.5935e-02,  3.3003e-02,  8.0919e-03,  4.1911e-02]],\n",
       "              \n",
       "                       [[-2.2015e-02, -2.8899e-02, -3.5189e-02, -1.5189e-02,  5.3904e-02],\n",
       "                        [ 5.9046e-02,  3.4546e-02, -5.1601e-02,  1.7236e-02,  2.5153e-02],\n",
       "                        [-5.8618e-02,  7.5740e-03,  2.2211e-03, -1.9309e-02,  3.6886e-02],\n",
       "                        [-1.7559e-02,  4.6140e-03, -2.3549e-02, -1.3346e-02,  3.0471e-02],\n",
       "                        [-6.2786e-02,  1.3635e-02, -1.2195e-02,  2.4058e-02,  5.6662e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9244e-02, -2.2299e-02,  6.2761e-02,  2.1466e-03, -5.8616e-02],\n",
       "                        [-2.2452e-02,  5.8716e-02,  4.2444e-03,  4.2035e-02, -3.1256e-02],\n",
       "                        [-2.3227e-02, -6.3238e-02, -1.0892e-02,  4.7195e-02, -5.9141e-02],\n",
       "                        [ 3.5335e-02,  1.9285e-02,  6.2078e-02, -6.0455e-02,  2.9776e-02],\n",
       "                        [-7.9040e-03,  2.3724e-03, -4.8565e-02,  7.5053e-03, -5.0735e-02]],\n",
       "              \n",
       "                       [[ 2.6670e-03, -1.0707e-02, -2.3492e-02,  4.9837e-02, -5.5329e-02],\n",
       "                        [-4.8756e-02,  6.2261e-02,  3.0339e-02, -4.7960e-03, -4.8484e-02],\n",
       "                        [ 5.8677e-02, -2.3276e-02,  5.4890e-02,  3.8242e-02, -4.9525e-02],\n",
       "                        [-1.7644e-02,  3.3168e-02,  5.2832e-02, -5.7800e-02, -5.6661e-02],\n",
       "                        [ 3.6981e-02, -4.4690e-02,  1.6037e-02, -4.0051e-02, -5.0302e-02]],\n",
       "              \n",
       "                       [[ 5.2741e-04, -4.1453e-02,  2.8974e-02,  1.8327e-02,  5.7259e-02],\n",
       "                        [-3.3225e-03,  5.9475e-02, -3.8283e-02,  3.2115e-02,  1.1121e-02],\n",
       "                        [-2.2994e-02,  3.2349e-02, -1.4226e-02, -8.3428e-03,  6.0642e-02],\n",
       "                        [ 1.7580e-02, -1.2781e-02,  5.6180e-03, -4.9371e-02, -3.8623e-02],\n",
       "                        [ 4.6587e-02, -4.9882e-02,  4.5199e-03, -2.1328e-02,  4.3469e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.4568e-02, -4.1989e-02,  4.6801e-03,  3.6237e-02,  4.2563e-02],\n",
       "                        [ 2.6836e-02, -2.8406e-02, -4.8459e-02, -1.4430e-02,  6.2579e-02],\n",
       "                        [-9.6998e-03,  3.9761e-02, -6.1565e-02, -3.8662e-03,  4.4452e-02],\n",
       "                        [-1.0457e-02,  1.1273e-02, -2.2106e-02, -1.7407e-02,  3.7937e-02],\n",
       "                        [ 5.3611e-02, -5.5724e-02, -1.4582e-02,  3.1548e-02, -5.5284e-02]],\n",
       "              \n",
       "                       [[-1.2768e-03, -2.9488e-02, -1.9673e-02,  1.0590e-02, -9.4183e-03],\n",
       "                        [ 1.4480e-02, -3.2286e-03,  5.1832e-02,  2.8751e-02, -4.1141e-02],\n",
       "                        [ 1.8364e-02, -2.8129e-02, -4.0038e-02, -9.3015e-03, -3.0789e-02],\n",
       "                        [ 1.2064e-04, -1.7399e-02, -4.1570e-02,  4.9726e-02,  3.1251e-02],\n",
       "                        [-2.2157e-02,  4.1634e-02,  1.7776e-02, -3.1612e-02,  3.0018e-02]],\n",
       "              \n",
       "                       [[ 1.2988e-02,  3.7467e-02,  2.1626e-02,  3.5144e-02,  1.5662e-02],\n",
       "                        [ 1.0549e-02,  2.8794e-02,  4.4559e-02,  2.0175e-02,  5.5810e-02],\n",
       "                        [-2.2037e-02, -6.3055e-02,  6.2172e-02,  2.0097e-02, -2.3455e-02],\n",
       "                        [-2.9729e-02,  6.2179e-02,  1.3344e-02, -1.2071e-02,  3.1711e-03],\n",
       "                        [ 1.4337e-02, -4.0016e-02, -2.8399e-02, -4.9892e-02,  6.2825e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4588e-02, -1.2585e-02, -2.2845e-02,  1.0302e-02, -5.1362e-02],\n",
       "                        [-3.2986e-02, -1.6244e-03,  1.2329e-02, -3.6751e-02,  1.6453e-02],\n",
       "                        [-5.9474e-04,  6.3718e-04,  4.0853e-02, -4.8484e-03,  1.4067e-02],\n",
       "                        [ 3.5687e-02, -1.6086e-03, -2.7179e-02,  7.3848e-03,  3.2231e-03],\n",
       "                        [ 5.0902e-02, -4.0250e-02, -1.8010e-02,  6.8720e-03, -6.1444e-02]],\n",
       "              \n",
       "                       [[-2.2550e-02,  5.9230e-02, -1.8955e-02, -2.5032e-02,  1.5797e-02],\n",
       "                        [ 8.9152e-03, -4.0047e-02, -3.5241e-02, -2.2237e-02, -5.8812e-02],\n",
       "                        [ 2.4294e-02,  8.8374e-03,  1.3340e-02,  4.5099e-02, -1.9442e-02],\n",
       "                        [ 4.0191e-02,  3.3374e-02, -2.6297e-02, -5.7811e-02, -5.9259e-02],\n",
       "                        [-4.5211e-02,  5.1161e-02, -1.0677e-02,  3.2190e-02,  3.1279e-02]],\n",
       "              \n",
       "                       [[ 3.2825e-02,  1.7402e-02, -5.7075e-02, -5.4329e-02,  9.3067e-05],\n",
       "                        [ 2.3045e-02, -5.0094e-03, -2.2618e-02, -4.4862e-02,  1.9635e-02],\n",
       "                        [-3.9581e-02,  9.8185e-03,  1.8985e-02,  5.5660e-02, -1.9427e-03],\n",
       "                        [ 5.6034e-02, -4.7043e-02,  5.9886e-02,  3.4174e-02, -1.7461e-02],\n",
       "                        [ 5.0940e-02, -4.2942e-04, -5.0761e-02, -5.2307e-02,  1.3390e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.7881e-02, -3.6706e-02,  5.2458e-03, -3.3896e-02,  8.5988e-04],\n",
       "                        [-3.4291e-02,  2.8527e-02,  1.7996e-02, -4.8983e-02,  5.1470e-02],\n",
       "                        [ 6.7137e-03, -3.0779e-02, -2.6556e-02, -4.0979e-02, -4.2274e-02],\n",
       "                        [-2.3502e-03, -4.7818e-02,  2.8098e-02, -4.8541e-02,  9.0493e-03],\n",
       "                        [ 1.9663e-02,  3.4185e-02, -5.2911e-03,  4.2159e-02,  3.6254e-02]],\n",
       "              \n",
       "                       [[ 5.9626e-02,  9.6441e-03,  4.6998e-02, -1.3475e-02,  4.6843e-02],\n",
       "                        [-4.5361e-02,  3.7047e-02, -3.2874e-02, -3.1752e-03, -3.3416e-02],\n",
       "                        [-3.8720e-02,  3.9305e-02,  2.6185e-02, -1.9631e-03,  9.0235e-03],\n",
       "                        [-4.0922e-02,  6.0830e-02, -6.9323e-03,  5.8466e-02, -7.7760e-03],\n",
       "                        [ 7.7961e-03, -4.3255e-02, -1.7974e-02,  2.3604e-02,  1.0166e-02]],\n",
       "              \n",
       "                       [[ 5.3796e-02,  4.8464e-02, -5.0703e-02,  5.1651e-02,  4.4033e-03],\n",
       "                        [-6.2558e-02,  4.3692e-03, -4.9273e-02,  6.1562e-02, -1.3746e-02],\n",
       "                        [-2.4352e-02, -1.2171e-02, -4.2169e-02, -2.1270e-02, -1.2698e-02],\n",
       "                        [-4.6658e-02, -3.5443e-02, -1.4580e-03, -3.9751e-02,  5.8334e-02],\n",
       "                        [ 5.9326e-02,  6.1290e-02, -6.0512e-03,  4.6057e-02, -1.3823e-02]]]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([-0.0613, -0.0037, -0.0612,  0.0267, -0.0208, -0.0237,  0.0164, -0.0468,\n",
       "                       0.0272,  0.0502,  0.0541,  0.0413, -0.0446,  0.0428,  0.0384,  0.0254,\n",
       "                      -0.0526,  0.0028,  0.0038,  0.0428])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0385,  0.0141, -0.0474,  ...,  0.0083,  0.0385, -0.0288],\n",
       "                      [ 0.0369,  0.0264, -0.0483,  ..., -0.0304,  0.0474, -0.0315],\n",
       "                      [ 0.0029, -0.0161,  0.0230,  ..., -0.0483,  0.0502,  0.0258],\n",
       "                      ...,\n",
       "                      [ 0.0040, -0.0033,  0.0506,  ..., -0.0384,  0.0538,  0.0518],\n",
       "                      [ 0.0388,  0.0264,  0.0455,  ..., -0.0068,  0.0164, -0.0298],\n",
       "                      [ 0.0035,  0.0011,  0.0086,  ..., -0.0242, -0.0497,  0.0354]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.0411, -0.0199, -0.0473,  0.0343, -0.0503, -0.0203,  0.0399,  0.0145,\n",
       "                      -0.0295, -0.0125,  0.0551,  0.0365,  0.0482, -0.0268,  0.0445, -0.0299,\n",
       "                      -0.0067, -0.0211,  0.0183,  0.0344,  0.0501,  0.0534,  0.0249, -0.0236,\n",
       "                      -0.0277,  0.0044,  0.0373, -0.0189, -0.0101,  0.0302,  0.0160,  0.0361,\n",
       "                      -0.0449, -0.0098,  0.0305, -0.0279, -0.0322,  0.0303, -0.0290, -0.0084,\n",
       "                       0.0323, -0.0097,  0.0455,  0.0015, -0.0376,  0.0290, -0.0182,  0.0150,\n",
       "                       0.0007, -0.0360])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0548, -0.0738, -0.1061,  0.0909,  0.0656,  0.0721, -0.1097, -0.1097,\n",
       "                       -0.0872,  0.0411,  0.1411, -0.0731,  0.1244, -0.1105, -0.0031,  0.0995,\n",
       "                        0.0562, -0.0304,  0.0328, -0.0737, -0.0813, -0.0578,  0.0482, -0.0585,\n",
       "                        0.0500, -0.0574, -0.0641, -0.1141,  0.1371,  0.1407,  0.0607,  0.0391,\n",
       "                       -0.1022, -0.1137, -0.1113, -0.0346,  0.1132, -0.1328, -0.1374,  0.0026,\n",
       "                       -0.0851,  0.0465,  0.0030, -0.0969,  0.0799, -0.1007,  0.0956, -0.0748,\n",
       "                        0.0239, -0.0815],\n",
       "                      [ 0.0889,  0.0503, -0.1172, -0.1284, -0.1041, -0.0214,  0.0652,  0.1064,\n",
       "                        0.1334, -0.1347,  0.0325, -0.0764,  0.0980,  0.0200,  0.0322, -0.0460,\n",
       "                        0.0128, -0.0568, -0.0106, -0.0319, -0.0206,  0.0534, -0.1104, -0.0470,\n",
       "                       -0.0629, -0.0144,  0.0753,  0.0596,  0.0481,  0.1251,  0.0534, -0.0451,\n",
       "                        0.0824,  0.0905, -0.0588, -0.0670,  0.1073, -0.0713, -0.0491,  0.0290,\n",
       "                       -0.0861, -0.0503, -0.1145,  0.1040,  0.0136, -0.0162, -0.0971, -0.0877,\n",
       "                        0.0693,  0.1241],\n",
       "                      [ 0.0461, -0.0863,  0.1323, -0.0907,  0.0781,  0.0617,  0.0893, -0.1325,\n",
       "                        0.0079,  0.1007,  0.1081, -0.1088, -0.0027,  0.0285, -0.0371,  0.0446,\n",
       "                       -0.0105, -0.0685,  0.1193,  0.0664,  0.0074, -0.0063, -0.1400, -0.0218,\n",
       "                        0.0716, -0.1276, -0.0586, -0.0304, -0.0614, -0.0969,  0.1208,  0.0244,\n",
       "                        0.1218, -0.0197,  0.1000, -0.1196, -0.0751, -0.0256,  0.0888,  0.0280,\n",
       "                        0.1355, -0.0722,  0.0372, -0.0376,  0.0746,  0.0902, -0.1087,  0.0403,\n",
       "                        0.0630, -0.1284],\n",
       "                      [-0.1293, -0.0230, -0.0944,  0.1007, -0.0373,  0.0818, -0.1308, -0.0281,\n",
       "                        0.0330, -0.0861,  0.1026,  0.0913,  0.0014,  0.0768,  0.1197,  0.0691,\n",
       "                       -0.0602, -0.0855,  0.0991,  0.0853,  0.0661,  0.1335,  0.1195, -0.0575,\n",
       "                        0.0244,  0.0163, -0.0969, -0.0880,  0.0391, -0.0733,  0.0100,  0.1092,\n",
       "                        0.1245,  0.0082, -0.1387,  0.0058,  0.0716, -0.0909, -0.0030, -0.0721,\n",
       "                        0.0595,  0.0267,  0.0177, -0.0187,  0.1150, -0.0480,  0.0300, -0.0795,\n",
       "                       -0.0460, -0.1311],\n",
       "                      [-0.1153,  0.1128, -0.0938, -0.1294,  0.0386,  0.0264,  0.0722,  0.0678,\n",
       "                       -0.1091,  0.0354,  0.0462,  0.0724, -0.0810,  0.0028,  0.0463,  0.1356,\n",
       "                       -0.1413, -0.0049,  0.1014, -0.0488,  0.0794,  0.0494,  0.0337,  0.0161,\n",
       "                        0.0362,  0.0524, -0.0820, -0.1223,  0.1240,  0.0871,  0.0792,  0.1047,\n",
       "                        0.1325, -0.0539, -0.0795, -0.0050, -0.0539, -0.0481,  0.0709,  0.1032,\n",
       "                        0.1065,  0.0694, -0.0572,  0.0999, -0.0605, -0.1204,  0.1035,  0.0649,\n",
       "                       -0.0965,  0.0213],\n",
       "                      [ 0.0300, -0.0841, -0.0388, -0.0464, -0.1090,  0.0145, -0.0811,  0.0395,\n",
       "                        0.1166, -0.1216, -0.1348, -0.1140, -0.1381, -0.1323, -0.1290,  0.0266,\n",
       "                        0.0449,  0.0449, -0.1242,  0.0489,  0.0817, -0.0484,  0.0533,  0.0265,\n",
       "                        0.0473, -0.1051,  0.1383,  0.0973, -0.0662,  0.0448,  0.0226,  0.0780,\n",
       "                        0.0884,  0.0472, -0.0302,  0.0609, -0.0894, -0.0854, -0.0124, -0.1243,\n",
       "                        0.1320,  0.1007,  0.1244, -0.0868,  0.0829, -0.0314, -0.1119, -0.1375,\n",
       "                        0.1354, -0.0269],\n",
       "                      [ 0.0039, -0.1311, -0.0309,  0.0196,  0.0729,  0.0061,  0.0311,  0.0630,\n",
       "                       -0.0607,  0.0607, -0.1239,  0.1021, -0.0649,  0.0356, -0.0213, -0.0290,\n",
       "                        0.0360, -0.0207,  0.0683,  0.1164, -0.0357, -0.0080, -0.1335,  0.0663,\n",
       "                        0.0613, -0.1231,  0.0739, -0.0351, -0.1031, -0.0122,  0.0205,  0.0231,\n",
       "                       -0.0218,  0.0196, -0.0956, -0.0295, -0.0224,  0.0997,  0.0375,  0.0154,\n",
       "                       -0.0425,  0.0232, -0.1277,  0.0759,  0.0177,  0.0861,  0.0112,  0.1309,\n",
       "                        0.0114, -0.0058],\n",
       "                      [-0.0385,  0.0143,  0.0526,  0.0836,  0.1123, -0.0079,  0.1196, -0.0865,\n",
       "                        0.0228,  0.0387,  0.0804, -0.0569, -0.1089, -0.1278,  0.0678, -0.0349,\n",
       "                       -0.0296,  0.1140,  0.0292, -0.0090, -0.0127, -0.0075, -0.0160,  0.0420,\n",
       "                       -0.0597,  0.1223, -0.1234, -0.1091, -0.0909, -0.0092,  0.1286, -0.0810,\n",
       "                       -0.1201, -0.1351, -0.1395, -0.0745, -0.0430, -0.1235,  0.0641, -0.1289,\n",
       "                       -0.0086, -0.1268,  0.1095,  0.0839,  0.1090, -0.0244, -0.0887,  0.0071,\n",
       "                       -0.0824, -0.0950],\n",
       "                      [ 0.0691, -0.0529,  0.0742,  0.1274, -0.0553,  0.0337, -0.1194, -0.1363,\n",
       "                        0.0616,  0.0206,  0.0791,  0.0698,  0.0919,  0.1344,  0.0526,  0.0568,\n",
       "                       -0.0107, -0.0839,  0.1116, -0.0038, -0.1128, -0.0668,  0.1403,  0.1129,\n",
       "                       -0.0317,  0.0663,  0.0147,  0.0011, -0.0498, -0.1313, -0.1137, -0.1214,\n",
       "                       -0.0082, -0.0058,  0.1184, -0.0202, -0.0721,  0.0392, -0.0568, -0.0159,\n",
       "                       -0.0565, -0.0234, -0.1011,  0.0481,  0.0191,  0.0396, -0.0278, -0.1138,\n",
       "                        0.0809,  0.0813],\n",
       "                      [-0.0360, -0.0761, -0.1002,  0.0707,  0.1248,  0.1210,  0.0944, -0.0314,\n",
       "                        0.1406, -0.1403,  0.0853, -0.0510,  0.0951,  0.0861, -0.0380, -0.0832,\n",
       "                       -0.1048, -0.0198,  0.0962,  0.0123, -0.0833, -0.0611, -0.0791, -0.1300,\n",
       "                        0.1323,  0.0630,  0.1291,  0.0359, -0.0979, -0.0655,  0.0216, -0.1214,\n",
       "                       -0.0865,  0.0154, -0.1277,  0.1319, -0.1044, -0.1284, -0.1058, -0.0972,\n",
       "                       -0.0405, -0.0577,  0.0955,  0.0667,  0.0494,  0.0255, -0.1236, -0.0216,\n",
       "                        0.1315,  0.1033]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.0656,  0.0954,  0.0984,  0.0173, -0.1017, -0.0776,  0.0082,  0.1016,\n",
       "                      -0.0967,  0.1045]))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6a88c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
