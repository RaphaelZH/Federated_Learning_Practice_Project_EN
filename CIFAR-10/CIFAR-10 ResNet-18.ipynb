{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8492bb64",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>\n",
    "\n",
    "- [Importation des bibliothèques](#toc1_)\n",
    "  - [Importation des paquets ou modules de la bibliothèque OpenFL](#toc1_1_)\n",
    "  - [Importation des paquets ou modules de la bibliothèque PyTorch](#toc1_2_)\n",
    "  - [Importation d’autres paquets ou modules requis](#toc1_3_)\n",
    "- [Définition du modèle d‘entraînement](#toc2_)\n",
    "  - [Définition des chargeurs de données](#toc2_1_)\n",
    "  - [Téléchargement du modèle de réseau CNN prédéfini](#toc2_2_)\n",
    "  - [Définition de la fonction d'inférence utilisée dans le test](#toc2_3_)\n",
    "- [Définition des règles de l'apprentissage fédéré](#toc3_)\n",
    "  - [Méthode de calcul de la moyenne des poids d'apprentissage fédéré](#toc3_1_)\n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6017fe",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Importation des bibliothèques](#toc0_)\n",
    "\n",
    "## <a id='toc1_1_'></a>[Importation des paquets ou modules de la bibliothèque OpenFL](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f63aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.experimental.workflow.interface import Aggregator, Collaborator, FLSpec\n",
    "from openfl.experimental.workflow.placement import aggregator, collaborator\n",
    "from openfl.experimental.workflow.runtime import LocalRuntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6e4731",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Importation des paquets ou modules de la bibliothèque PyTorch](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b89c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42f022",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Importation d’autres paquets ou modules requis](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d76255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from termcolor import cprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b634c6",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Définition du modèle d‘entraînement](#toc0_)\n",
    "\n",
    "## <a id='toc2_1_'></a>[Définition des chargeurs de données](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2aaf920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32, 50000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/tmp/files/\"\n",
    "\n",
    "tensor_cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "tensor_images = torch.stack([tensor_image for tensor_image, _ in tensor_cifar10], dim=3)\n",
    "\n",
    "tensor_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1a07f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4914, 0.4822, 0.4465])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_mean = tensor_images.view(3, -1).mean(dim=1)\n",
    "tensor_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a726a54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2470, 0.2435, 0.2616])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_std = tensor_images.view(3, -1).std(dim=1)\n",
    "tensor_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ffab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(tensor_mean, tensor_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(\n",
    "    \"/tmp/files/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "cifar10_test = datasets.CIFAR10(\n",
    "    \"/tmp/files/\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f439e5d",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Téléchargement du modèle de réseau CNN prédéfini](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed9fc735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps:0\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01738796",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18()\n",
    "model.conv1 = nn.Conv2d(\n",
    "    3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
    ")\n",
    "model.fc = nn.Linear(in_features=512, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7045df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
      "            Conv2d-5           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 16, 16]             128\n",
      "              ReLU-7           [-1, 64, 16, 16]               0\n",
      "            Conv2d-8           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
      "             ReLU-10           [-1, 64, 16, 16]               0\n",
      "       BasicBlock-11           [-1, 64, 16, 16]               0\n",
      "           Conv2d-12           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 16, 16]             128\n",
      "             ReLU-14           [-1, 64, 16, 16]               0\n",
      "           Conv2d-15           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 16, 16]             128\n",
      "             ReLU-17           [-1, 64, 16, 16]               0\n",
      "       BasicBlock-18           [-1, 64, 16, 16]               0\n",
      "           Conv2d-19            [-1, 128, 8, 8]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 8, 8]             256\n",
      "             ReLU-21            [-1, 128, 8, 8]               0\n",
      "           Conv2d-22            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 8, 8]             256\n",
      "           Conv2d-24            [-1, 128, 8, 8]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 8, 8]             256\n",
      "             ReLU-26            [-1, 128, 8, 8]               0\n",
      "       BasicBlock-27            [-1, 128, 8, 8]               0\n",
      "           Conv2d-28            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 8, 8]             256\n",
      "             ReLU-30            [-1, 128, 8, 8]               0\n",
      "           Conv2d-31            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 8, 8]             256\n",
      "             ReLU-33            [-1, 128, 8, 8]               0\n",
      "       BasicBlock-34            [-1, 128, 8, 8]               0\n",
      "           Conv2d-35            [-1, 256, 4, 4]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 4, 4]             512\n",
      "             ReLU-37            [-1, 256, 4, 4]               0\n",
      "           Conv2d-38            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 4, 4]             512\n",
      "           Conv2d-40            [-1, 256, 4, 4]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 4, 4]             512\n",
      "             ReLU-42            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-43            [-1, 256, 4, 4]               0\n",
      "           Conv2d-44            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 4, 4]             512\n",
      "             ReLU-46            [-1, 256, 4, 4]               0\n",
      "           Conv2d-47            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 4, 4]             512\n",
      "             ReLU-49            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-50            [-1, 256, 4, 4]               0\n",
      "           Conv2d-51            [-1, 512, 2, 2]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-53            [-1, 512, 2, 2]               0\n",
      "           Conv2d-54            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 2, 2]           1,024\n",
      "           Conv2d-56            [-1, 512, 2, 2]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-58            [-1, 512, 2, 2]               0\n",
      "       BasicBlock-59            [-1, 512, 2, 2]               0\n",
      "           Conv2d-60            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-62            [-1, 512, 2, 2]               0\n",
      "           Conv2d-63            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-65            [-1, 512, 2, 2]               0\n",
      "       BasicBlock-66            [-1, 512, 2, 2]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,173,962\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.13\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 47.77\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, next(iter(cifar10_test))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7933b052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m  conv1.weight ............................................. 1728  \u001b[0m\n",
      "\u001b[35m  bn1.weight ................................................. 64  \u001b[0m\n",
      "\u001b[35m  bn1.bias ................................................... 64  \u001b[0m\n",
      "\u001b[35m  layer1.0.conv1.weight ................................... 36864  \u001b[0m\n",
      "\u001b[35m  layer1.0.bn1.weight ........................................ 64  \u001b[0m\n",
      "\u001b[35m  layer1.0.bn1.bias .......................................... 64  \u001b[0m\n",
      "\u001b[35m  layer1.0.conv2.weight ................................... 36864  \u001b[0m\n",
      "\u001b[35m  layer1.0.bn2.weight ........................................ 64  \u001b[0m\n",
      "\u001b[35m  layer1.0.bn2.bias .......................................... 64  \u001b[0m\n",
      "\u001b[35m  layer1.1.conv1.weight ................................... 36864  \u001b[0m\n",
      "\u001b[35m  layer1.1.bn1.weight ........................................ 64  \u001b[0m\n",
      "\u001b[35m  layer1.1.bn1.bias .......................................... 64  \u001b[0m\n",
      "\u001b[35m  layer1.1.conv2.weight ................................... 36864  \u001b[0m\n",
      "\u001b[35m  layer1.1.bn2.weight ........................................ 64  \u001b[0m\n",
      "\u001b[35m  layer1.1.bn2.bias .......................................... 64  \u001b[0m\n",
      "\u001b[35m  layer2.0.conv1.weight ................................... 73728  \u001b[0m\n",
      "\u001b[35m  layer2.0.bn1.weight ....................................... 128  \u001b[0m\n",
      "\u001b[35m  layer2.0.bn1.bias ......................................... 128  \u001b[0m\n",
      "\u001b[35m  layer2.0.conv2.weight .................................. 147456  \u001b[0m\n",
      "\u001b[35m  layer2.0.bn2.weight ....................................... 128  \u001b[0m\n",
      "\u001b[35m  layer2.0.bn2.bias ......................................... 128  \u001b[0m\n",
      "\u001b[35m  layer2.0.downsample.0.weight ............................. 8192  \u001b[0m\n",
      "\u001b[35m  layer2.0.downsample.1.weight .............................. 128  \u001b[0m\n",
      "\u001b[35m  layer2.0.downsample.1.bias ................................ 128  \u001b[0m\n",
      "\u001b[35m  layer2.1.conv1.weight .................................. 147456  \u001b[0m\n",
      "\u001b[35m  layer2.1.bn1.weight ....................................... 128  \u001b[0m\n",
      "\u001b[35m  layer2.1.bn1.bias ......................................... 128  \u001b[0m\n",
      "\u001b[35m  layer2.1.conv2.weight .................................. 147456  \u001b[0m\n",
      "\u001b[35m  layer2.1.bn2.weight ....................................... 128  \u001b[0m\n",
      "\u001b[35m  layer2.1.bn2.bias ......................................... 128  \u001b[0m\n",
      "\u001b[35m  layer3.0.conv1.weight .................................. 294912  \u001b[0m\n",
      "\u001b[35m  layer3.0.bn1.weight ....................................... 256  \u001b[0m\n",
      "\u001b[35m  layer3.0.bn1.bias ......................................... 256  \u001b[0m\n",
      "\u001b[35m  layer3.0.conv2.weight .................................. 589824  \u001b[0m\n",
      "\u001b[35m  layer3.0.bn2.weight ....................................... 256  \u001b[0m\n",
      "\u001b[35m  layer3.0.bn2.bias ......................................... 256  \u001b[0m\n",
      "\u001b[35m  layer3.0.downsample.0.weight ............................ 32768  \u001b[0m\n",
      "\u001b[35m  layer3.0.downsample.1.weight .............................. 256  \u001b[0m\n",
      "\u001b[35m  layer3.0.downsample.1.bias ................................ 256  \u001b[0m\n",
      "\u001b[35m  layer3.1.conv1.weight .................................. 589824  \u001b[0m\n",
      "\u001b[35m  layer3.1.bn1.weight ....................................... 256  \u001b[0m\n",
      "\u001b[35m  layer3.1.bn1.bias ......................................... 256  \u001b[0m\n",
      "\u001b[35m  layer3.1.conv2.weight .................................. 589824  \u001b[0m\n",
      "\u001b[35m  layer3.1.bn2.weight ....................................... 256  \u001b[0m\n",
      "\u001b[35m  layer3.1.bn2.bias ......................................... 256  \u001b[0m\n",
      "\u001b[35m  layer4.0.conv1.weight ................................. 1179648  \u001b[0m\n",
      "\u001b[35m  layer4.0.bn1.weight ....................................... 512  \u001b[0m\n",
      "\u001b[35m  layer4.0.bn1.bias ......................................... 512  \u001b[0m\n",
      "\u001b[35m  layer4.0.conv2.weight ................................. 2359296  \u001b[0m\n",
      "\u001b[35m  layer4.0.bn2.weight ....................................... 512  \u001b[0m\n",
      "\u001b[35m  layer4.0.bn2.bias ......................................... 512  \u001b[0m\n",
      "\u001b[35m  layer4.0.downsample.0.weight ........................... 131072  \u001b[0m\n",
      "\u001b[35m  layer4.0.downsample.1.weight .............................. 512  \u001b[0m\n",
      "\u001b[35m  layer4.0.downsample.1.bias ................................ 512  \u001b[0m\n",
      "\u001b[35m  layer4.1.conv1.weight ................................. 2359296  \u001b[0m\n",
      "\u001b[35m  layer4.1.bn1.weight ....................................... 512  \u001b[0m\n",
      "\u001b[35m  layer4.1.bn1.bias ......................................... 512  \u001b[0m\n",
      "\u001b[35m  layer4.1.conv2.weight ................................. 2359296  \u001b[0m\n",
      "\u001b[35m  layer4.1.bn2.weight ....................................... 512  \u001b[0m\n",
      "\u001b[35m  layer4.1.bn2.bias ......................................... 512  \u001b[0m\n",
      "\u001b[35m  fc.weight ................................................ 5120  \u001b[0m\n",
      "\u001b[35m  fc.bias .................................................... 10  \u001b[0m\n",
      "\u001b[35m _________________________________________________________________ \u001b[0m\n",
      "\u001b[35m  total parameters ..................................... 11173962  \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    length = 67\n",
    "    names = [n for (n, p) in model.named_parameters() if p.requires_grad]\n",
    "    name = \"total parameters\"\n",
    "    names.append(name)\n",
    "    max_length = max(map(len, names))\n",
    "    formatted_names = [f\"{f'  {n} ':.<{max_length + 3}}\" for n in names]\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    params.append(sum(params))\n",
    "    formatted_params = [f\"{f' {p}  ':.>{length - max_length - 3}}\" for p in params]\n",
    "\n",
    "    for n, p in zip(formatted_names[:-1], formatted_params[:-1]):\n",
    "        cprint((n + p), \"magenta\")\n",
    "    cprint(\" \" + \"_\" * (length - 2) + \" \", \"magenta\")\n",
    "    cprint(\n",
    "        (formatted_names[-1] + formatted_params[-1]),\n",
    "        \"magenta\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "\n",
    "    return names, params\n",
    "\n",
    "\n",
    "names, params = count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9993220e",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[Définition de la fonction d'inférence utilisée dans le test](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13b360d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(network, test_loader):\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = network(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction=\"sum\").item()\n",
    "            pred = output.data.max(dim=1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    cprint(\n",
    "        \"Test set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\".format(\n",
    "            test_loss,\n",
    "            correct,\n",
    "            len(test_loader.dataset),\n",
    "            100.0 * correct / len(test_loader.dataset),\n",
    "        ),\n",
    "        \"magenta\",\n",
    "        attrs=[\"underline\"],\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "    return float(correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f8c156a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[35mTest set: Avg. loss: 2.5568, Accuracy: 1014/10000 (10%)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10140000283718109"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(cifar10_test, batch_size=500, shuffle=False)\n",
    "\n",
    "inference(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1dabb0",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Définition des règles de l'apprentissage fédéré](#toc0_)\n",
    "\n",
    "## <a id='toc3_1_'></a>[Méthode de calcul de la moyenne des poids d'apprentissage fédéré](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59d93477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedAvg(models, weights=None):\n",
    "    new_model = models[0]\n",
    "    state_dicts = [model.state_dict() for model in models]\n",
    "    state_dict = new_model.state_dict()\n",
    "    for key in models[1].state_dict():\n",
    "        if state_dict[key].dim() != 0:\n",
    "            state_dict[key] = torch.from_numpy(\n",
    "                np.average(\n",
    "                    [state[key].cpu().numpy() for state in state_dicts],\n",
    "                    axis=0,\n",
    "                    weights=weights,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            state_dict[key] = torch.from_numpy(\n",
    "                np.average(\n",
    "                    [state[key].reshape(1).cpu().numpy() for state in state_dicts],\n",
    "                    axis=0,\n",
    "                    weights=weights,\n",
    "                )\n",
    "            )\n",
    "    new_model.load_state_dict(state_dict)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3d20ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregator step \"start\" registered\n",
      "Collaborator step \"aggregated_model_validation\" registered\n",
      "Collaborator step \"train\" registered\n",
      "Collaborator step \"local_model_validation\" registered\n",
      "Aggregator step \"join\" registered\n",
      "Aggregator step \"end\" registered\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "log_interval = 10\n",
    "momentum = 0.5\n",
    "\n",
    "\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "\n",
    "class FederatedFlow(FLSpec):\n",
    "\n",
    "    def __init__(self, model=None, optimizer=None, rounds=3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Importe un modèle personnalisé et ajoute le bon algorithme d’optimisation pour ce dernier.\n",
    "        if model is not None:\n",
    "            self.model = model\n",
    "            self.optimizer = optimizer\n",
    "        # Chargez le modèle `Net()` et configurez l'optimiseur pour qu'il s'applique uniquement à ce\n",
    "        # modèle.\n",
    "        else:\n",
    "            self.model = Net()\n",
    "            self.optimizer = optim.SGD(\n",
    "                self.model.parameters(), lr=learning_rate, momentum=momentum\n",
    "            )\n",
    "        self.rounds = rounds\n",
    "\n",
    "    # Un agrégateur est le nœud central de l'apprentissage fédéré.\n",
    "\n",
    "    # L'agrégateur commence par un modèle et un optimiseur transmis de manière facultative.\n",
    "\n",
    "    # L'agrégateur commence le flux avec la tâche de `start`, où la liste des collaborateurs est\n",
    "    # extraite de l'exécution (`self.collaborators = self.runtime.collaborators`) et est ensuite\n",
    "    # utilisée comme liste de participants pour exécuterla tâche énumérée dans `self.next`,\n",
    "    # `aggregated_model_validation`.\n",
    "    @aggregator\n",
    "    def start(self):\n",
    "        cprint(\"Performing initialization for model\", \"black\", attrs=[\"bold\"])\n",
    "        self.collaborators = self.runtime.collaborators\n",
    "        self.private = 10\n",
    "        self.current_round = 0\n",
    "        self.next(\n",
    "            self.aggregated_model_validation,\n",
    "            foreach=\"collaborators\",\n",
    "            exclude=[\"private\"],\n",
    "        )\n",
    "\n",
    "    # Le modèle, l'optimiseur et tout ce qui n'est pas explicitement exclu de la fonction suivante\n",
    "    # seront transmis de la fonction de `start` de l'agrégateur à la tâche\n",
    "    # `aggregated_model_validation` du collaborateur.\n",
    "\n",
    "    # L’endroit où les tâches sont exécutées est déterminé par le décorateur de placement qui\n",
    "    # précède chaque définition de tâche (`@aggregator` ou `@collaborator`).\n",
    "\n",
    "    # Une fois que chaque collaborateur (défini dans l’exécution) a terminé la tâche\n",
    "    # `aggregated_model_validation`, il transmet son état actuel à la tâche `train`, de `train` à\n",
    "    # `local_model_validation`, et enfin à `join` à l'agrégateur.\n",
    "\n",
    "    # C'est au niveau de `join` qu'une moyenne des poids des modèles est calculée et que le tour\n",
    "    # suivant peut commencer.\n",
    "    @collaborator\n",
    "    def aggregated_model_validation(self):\n",
    "        cprint(\n",
    "            f\"Performing aggregated model validation for collaborator {self.input}\",\n",
    "            \"red\",\n",
    "            attrs=[\"bold\"],\n",
    "        )\n",
    "        self.agg_validation_score = inference(self.model, self.test_loader)\n",
    "        cprint(\n",
    "            f\"{self.input} value of {self.agg_validation_score}\",\n",
    "            \"red\",\n",
    "            attrs=[\"underline\"],\n",
    "        )\n",
    "        self.next(self.train)\n",
    "\n",
    "    @collaborator\n",
    "    def train(self):\n",
    "        if model is not None:\n",
    "            self.model = model\n",
    "            self.optimizer = optimizer\n",
    "        else:\n",
    "            self.model = Net()\n",
    "            self.optimizer = optim.SGD(\n",
    "                self.model.parameters(), lr=learning_rate, momentum=momentum\n",
    "            )\n",
    "        self.model.train()\n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                cprint(\n",
    "                    \"Train Epoch: 1 [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                        batch_idx * len(data),\n",
    "                        len(self.train_loader.dataset),\n",
    "                        100.0 * batch_idx / len(self.train_loader),\n",
    "                        loss.item(),\n",
    "                    ),\n",
    "                    \"yellow\",\n",
    "                )\n",
    "                self.loss = loss.item()\n",
    "                torch.save(self.model.state_dict(), \"model.pth\")\n",
    "                torch.save(self.optimizer.state_dict(), \"optimizer.pth\")\n",
    "        self.training_completed = True\n",
    "        self.next(self.local_model_validation)\n",
    "\n",
    "    @collaborator\n",
    "    def local_model_validation(self):\n",
    "        self.local_validation_score = inference(self.model, self.test_loader)\n",
    "        cprint(\n",
    "            f\"Doing local model validation for collaborator {self.input}: \\\n",
    "                {self.local_validation_score}\",\n",
    "            \"white\",\n",
    "        )\n",
    "        self.next(self.join, exclude=[\"training_completed\"])\n",
    "\n",
    "    @aggregator\n",
    "    def join(self, inputs):\n",
    "        self.average_loss = sum(input.loss for input in inputs) / len(inputs)\n",
    "        self.aggregated_model_accuracy = sum(\n",
    "            input.agg_validation_score for input in inputs\n",
    "        ) / len(inputs)\n",
    "        self.local_model_accuracy = sum(\n",
    "            input.local_validation_score for input in inputs\n",
    "        ) / len(inputs)\n",
    "        cprint(\n",
    "            f\"Average aggregated model validation values = \\\n",
    "                {self.aggregated_model_accuracy}\",\n",
    "            \"green\",\n",
    "        )\n",
    "        cprint(f\"Average training loss = {self.average_loss}\", \"green\")\n",
    "        cprint(\n",
    "            f\"Average local model validation values = \\\n",
    "            {self.local_model_accuracy}\",\n",
    "            \"green\",\n",
    "        )\n",
    "        self.model = FedAvg([input.model for input in inputs])\n",
    "        self.optimizer = [input.optimizer for input in inputs][0]\n",
    "        self.current_round += 1\n",
    "        if self.current_round < self.rounds:\n",
    "            self.next(\n",
    "                self.aggregated_model_validation,\n",
    "                foreach=\"collaborators\",\n",
    "                exclude=[\"private\"],\n",
    "            )\n",
    "        else:\n",
    "            self.next(self.end)\n",
    "\n",
    "    @aggregator\n",
    "    def end(self):\n",
    "        cprint(\"This is the end of the flow\", \"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b96e3045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local runtime collaborators = ['Portland', 'Seattle', 'Chandler', 'Bangalore']\n"
     ]
    }
   ],
   "source": [
    "batch_size_train = 64\n",
    "\n",
    "# Setup participants\n",
    "aggregator = Aggregator()\n",
    "aggregator.private_attributes = {}\n",
    "\n",
    "# Setup collaborators with private attributes\n",
    "collaborator_names = [\"Portland\", \"Seattle\", \"Chandler\", \"Bangalore\"]\n",
    "collaborators = [Collaborator(name=name) for name in collaborator_names]\n",
    "for idx, collaborator in enumerate(collaborators):\n",
    "    local_train = deepcopy(cifar10_train)\n",
    "    local_test = deepcopy(cifar10_test)\n",
    "    local_train.data = cifar10_train.data[idx :: len(collaborators)]\n",
    "    local_train.targets = cifar10_train.targets[idx :: len(collaborators)]\n",
    "    local_test.data = cifar10_test.data[idx :: len(collaborators)]\n",
    "    local_test.targets = cifar10_test.targets[idx :: len(collaborators)]\n",
    "    collaborator.private_attributes = {\n",
    "        \"train_loader\": DataLoader(\n",
    "            local_train, batch_size=batch_size_train, shuffle=True\n",
    "        ),\n",
    "        \"test_loader\": DataLoader(\n",
    "            local_test, batch_size=batch_size_train, shuffle=True\n",
    "        ),\n",
    "    }\n",
    "\n",
    "local_runtime = LocalRuntime(\n",
    "    aggregator=aggregator, collaborators=collaborators, backend=\"single_process\"\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Local runtime collaborators = {local_runtime.collaborators}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5494deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.environ.get(\"USERNAME\") is None:\n",
    "    os.environ[\"USERNAME\"] = \"Hao\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8018e1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haozhang\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "print(getpass.getuser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edbaff16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created flow FederatedFlow\n",
      "\n",
      "Calling start\n",
      "\u001b[94m\u001b[1m\u001b[30mPerforming initialization for model\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for start\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for start\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 2.5622, Accuracy: 251/2500 (10%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.10040000081062317\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 2.447564\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 1.790269\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 1.883020\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 1.665812\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 1.647754\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 1.768708\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 1.656770\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 1.415329\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 1.444500\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 1.361685\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 1.479390\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 1.626428\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 1.617099\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 1.389419\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 1.209319\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 1.150513\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 1.229169\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 1.224011\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 1.259834\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 1.454585\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 1.4020, Accuracy: 1225/2500 (49%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.49000000953674316\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 2.5722, Accuracy: 244/2500 (10%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.09759999811649323\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 1.526978\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 1.227921\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 1.058721\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 1.539656\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 1.287427\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 1.448374\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 1.492842\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 1.218305\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 1.275304\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 1.101582\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 1.125499\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 1.169226\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 1.055567\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 1.171490\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 1.235579\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 1.006916\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 1.088658\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 1.201213\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.941327\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 1.219251\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 1.2181, Accuracy: 1408/2500 (56%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.5631999969482422\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 2.5542, Accuracy: 268/2500 (11%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.10719999670982361\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 1.174515\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 1.245870\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 1.168590\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 1.164016\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 1.121115\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 1.252134\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 1.025999\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 1.017739\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 1.303985\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 1.014216\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 1.084743\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.926041\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.809927\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.800906\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.914065\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 1.169560\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 1.153268\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 1.145079\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.915639\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.888905\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 1.1024, Accuracy: 1520/2500 (61%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.6079999804496765\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 2.5388, Accuracy: 251/2500 (10%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.10040000081062317\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.994109\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.942293\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 1.308469\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.805575\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.815618\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.729448\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 1.009454\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.925210\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 1.157617\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.963367\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 1.076038\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 1.011652\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.991672\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.839792\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.950371\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.964188\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 1.088637\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.863990\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.851822\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 1.084795\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.9767, Accuracy: 1652/2500 (66%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.6607999801635742\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.10139999911189079\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 1.1618839651346207\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.580499991774559\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 1.0063, Accuracy: 1613/2500 (65%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.6452000141143799\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.715262\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 1.131780\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.604129\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.935317\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 1.060364\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 1.029629\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.828424\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.776818\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.383101\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.758380\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 1.103781\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.818621\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.641986\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.916738\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.892705\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.967161\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.668456\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.787378\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.879415\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.760025\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8837, Accuracy: 1762/2500 (70%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.704800009727478\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 1.0100, Accuracy: 1621/2500 (65%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.6484000086784363\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.720084\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.665680\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.693816\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.788654\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.882631\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.764019\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.983836\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.896916\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 1.122377\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.725517\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.529954\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.605010\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.617614\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.806540\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.996758\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.797206\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.746096\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.749756\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.524210\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.658142\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8943, Accuracy: 1705/2500 (68%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.6819999814033508\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 1.0138, Accuracy: 1600/2500 (64%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.6399999856948853\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.754631\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.872455\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.805160\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.792006\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.709220\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.535515\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.676755\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.894876\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.741156\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.638018\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.750563\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.619362\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.566170\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.522478\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.896019\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.824780\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.572666\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.716349\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.897226\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.732287\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7587, Accuracy: 1840/2500 (74%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.7360000014305115\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.9767, Accuracy: 1652/2500 (66%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.6607999801635742\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.691393\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.802011\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.692740\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.844826\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.673651\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.785429\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.650809\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.756710\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.739666\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.688181\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.535226\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.591498\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.620599\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.762960\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.525879\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.507364\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.498508\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.405563\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.637809\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.553641\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7518, Accuracy: 1850/2500 (74%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.7400000095367432\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.6485999971628189\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.6760237216949463\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.7157000005245209\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7495, Accuracy: 1858/2500 (74%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.7432000041007996\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.509922\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.776087\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.651825\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.596148\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.561186\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.502786\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.672871\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.715175\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.579070\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.777086\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.811259\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.829758\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.498350\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.511656\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.508954\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.425917\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.457835\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.595597\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.805174\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.418040\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7231, Accuracy: 1885/2500 (75%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.7540000081062317\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7795, Accuracy: 1851/2500 (74%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.7404000163078308\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.486238\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.443025\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.762877\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.801123\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.756750\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.465317\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.710003\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.490519\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.675815\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.479340\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.788181\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.676952\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.505627\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.800565\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.219540\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.730803\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.570242\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.716181\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.852281\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.554836\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7490, Accuracy: 1852/2500 (74%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.7408000230789185\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7858, Accuracy: 1813/2500 (73%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.7251999974250793\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.546576\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.567499\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.466895\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.485282\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.587635\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.649298\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.643572\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.572270\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.425081\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.312934\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.690071\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.633660\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.486421\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.534541\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.535266\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.569810\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.319701\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.581193\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.401441\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.422590\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6673, Accuracy: 1917/2500 (77%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.7667999863624573\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7518, Accuracy: 1850/2500 (74%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.7400000095367432\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.470371\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.899836\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.432301\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.557574\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.493942\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.478520\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.716865\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.431295\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.423438\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.535530\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.463073\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.511033\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.374743\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.424488\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.667519\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.506435\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.717427\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.508700\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.429867\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.685697\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6522, Accuracy: 1952/2500 (78%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.7807999849319458\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.7372000068426132\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.5202907994389534\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.7606000006198883\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6848, Accuracy: 1937/2500 (77%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.7748000025749207\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.493972\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.436092\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.581314\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.418707\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.559124\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.441259\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.435820\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.509713\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.550812\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.592425\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.342140\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.721398\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.474564\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.490132\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.620574\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.313461\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.372405\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.374997\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.342686\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.304159\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6046, Accuracy: 2007/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.8027999997138977\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7164, Accuracy: 1886/2500 (75%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.7544000148773193\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.587901\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.427855\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.481221\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.631079\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.293002\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.413688\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.545157\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.285510\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.461020\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.317638\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.287291\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.356781\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.376890\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.454450\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.420385\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.479500\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.378622\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.525142\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.400973\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.340335\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6766, Accuracy: 1919/2500 (77%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.7675999999046326\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7108, Accuracy: 1894/2500 (76%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.7576000094413757\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.487919\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.394808\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.638785\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.453142\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.311327\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.393197\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.348088\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.438411\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.337277\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.420688\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.364685\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.390613\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.333414\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.496369\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.647385\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.596890\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.576147\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.384182\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.670876\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.317221\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7236, Accuracy: 1929/2500 (77%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.7716000080108643\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6522, Accuracy: 1952/2500 (78%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.7807999849319458\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.400360\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.512318\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.261467\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.403273\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.543582\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.566259\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.392530\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.331338\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.316566\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.277747\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.435947\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.393494\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.280747\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.204723\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.296285\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.561963\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.474055\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.681752\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.366383\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.377454\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6343, Accuracy: 1993/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.7972000241279602\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.7669000029563904\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.3347921371459961\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.7848000079393387\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6264, Accuracy: 1988/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.795199990272522\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.378269\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.601871\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.452006\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.347204\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.380220\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.372566\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.416683\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.234040\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.279224\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.479881\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.286226\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.482521\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.241067\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.417526\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.487930\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.325873\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.365430\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.399589\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.347461\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.246837\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6121, Accuracy: 2005/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.8019999861717224\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6581, Accuracy: 1944/2500 (78%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.7775999903678894\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.374999\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.552411\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.314102\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.306340\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.309032\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.343587\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.272782\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.222865\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.201365\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.336628\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.617700\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.161830\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.445005\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.436822\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.380518\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.495611\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.303035\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.501407\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.298287\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.540355\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6161, Accuracy: 1998/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.7991999983787537\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6516, Accuracy: 1979/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.7915999889373779\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.216684\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.302574\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.275706\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.710450\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.262634\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.340598\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.148219\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.393721\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.307845\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.239185\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.190676\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.325008\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.292246\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.306841\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.315779\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.210939\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.319513\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.413635\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.242032\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.366475\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6858, Accuracy: 1956/2500 (78%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.7824000120162964\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6343, Accuracy: 1993/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.7972000241279602\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.342946\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.283901\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.216369\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.355965\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.285252\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.190833\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.345260\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.147746\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.278532\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.438226\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.392015\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.481879\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.218099\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.249161\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.183027\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.318395\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.272364\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.297774\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.409035\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.398485\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6664, Accuracy: 1981/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.7924000024795532\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.7903999984264374\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.38803816959261894\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.7939999997615814\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6546, Accuracy: 1997/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.798799991607666\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.456952\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.377845\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.218501\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.211550\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.218716\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.263293\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.286039\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.232446\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.232966\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.165253\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.283065\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.362248\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.248382\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.109304\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.316438\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.303118\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.174974\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.359265\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.178102\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.312835\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6571, Accuracy: 2008/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.8032000064849854\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6797, Accuracy: 1957/2500 (78%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.782800018787384\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.348657\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.451490\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.264792\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.389742\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.310446\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.278630\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.103484\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.137176\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.192969\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.422541\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.153915\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.271039\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.284190\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.103585\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.271345\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.264157\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.234676\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.350238\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.246251\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.405907\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6931, Accuracy: 1965/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.7860000133514404\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7032, Accuracy: 1963/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.7851999998092651\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.337342\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.287728\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.221746\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.177655\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.351689\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.217470\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.125275\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.239940\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.282610\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.190322\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.151066\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.261816\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.221479\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.152610\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.261579\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.226270\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.406506\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.224330\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.357596\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.225141\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7236, Accuracy: 1971/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.7883999943733215\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6664, Accuracy: 1981/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.7924000024795532\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.302407\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.248554\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.232436\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.134961\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.149543\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.100808\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.139187\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.151460\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.366226\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.208919\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.108479\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.216450\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.125070\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.052196\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.174126\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.075908\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.198161\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.242080\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.256062\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.135677\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7160, Accuracy: 2003/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.8011999726295471\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.7898000031709671\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.26988981664180756\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.7946999967098236\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7435, Accuracy: 1997/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.798799991607666\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.182750\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.268521\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.152866\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.214574\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.147444\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.139464\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.336659\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.183326\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.217571\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.145600\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.186642\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.176405\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.169985\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.147109\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.286621\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.292339\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.161841\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.075981\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.306555\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.124129\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7066, Accuracy: 2024/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.8095999956130981\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7812, Accuracy: 1956/2500 (78%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.7824000120162964\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.099806\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.221362\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.218799\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.283351\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.130919\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.204694\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.339215\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.151974\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.091708\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.199769\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.182934\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.373509\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.200163\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.164312\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.132014\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.227506\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.112067\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.073539\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.190415\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.109765\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7811, Accuracy: 1978/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.7911999821662903\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7741, Accuracy: 1984/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.7936000227928162\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.113742\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.146552\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.079771\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.148975\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.151986\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.123679\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.238302\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.136299\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.087624\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.129892\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.136764\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.175697\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.113108\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.087485\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.133359\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.099061\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.137271\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.085127\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.358460\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.374814\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7436, Accuracy: 2016/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.8064000010490417\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7160, Accuracy: 2003/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.8011999726295471\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.190007\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.236424\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.123281\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.114546\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.135599\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.158495\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.216492\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.305077\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.188054\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.204336\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.061801\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.125669\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.121958\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.150585\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.089276\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.205483\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.108572\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.089829\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.161824\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.076523\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7394, Accuracy: 2023/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.8091999888420105\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.7939999997615814\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.17130780965089798\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.8040999919176102\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7919, Accuracy: 2010/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.8040000200271606\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.171959\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.225302\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.266629\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.080806\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.158002\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.173381\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.157053\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.050661\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.164449\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.214075\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.089862\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.089066\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.152167\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.050025\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.048766\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.040086\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.146001\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.125054\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.111618\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.255419\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7667, Accuracy: 2036/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.8144000172615051\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8096, Accuracy: 1986/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.7943999767303467\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.133826\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.130633\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.317773\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.180996\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.093029\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.163299\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.265654\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.183390\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.071828\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.141600\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.086521\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.123338\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.084064\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.095808\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.273902\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.103659\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.285814\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.085766\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.096526\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.089185\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7918, Accuracy: 2005/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.8019999861717224\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8110, Accuracy: 1974/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.7896000146865845\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.128697\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.251280\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.161454\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.213500\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.114552\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.115726\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.145837\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.141636\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.128773\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.193068\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.164555\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.104529\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.179239\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.062761\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.096531\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.037870\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.040368\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.039555\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.067656\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.123127\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8376, Accuracy: 1982/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.7928000092506409\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7394, Accuracy: 2023/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.8091999888420105\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.150701\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.052017\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.137107\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.081821\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.077519\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.048705\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.098746\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.065277\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.126544\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.311977\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.089037\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.208930\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.141768\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.094904\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.068647\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.031133\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.078182\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.069755\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.026548\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.292855\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7734, Accuracy: 2035/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.8140000104904175\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.7993000000715256\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.19014617428183556\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.8058000057935715\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7939, Accuracy: 1996/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.7983999848365784\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.128702\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.194430\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.127881\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.050800\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.201891\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.105398\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.029325\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.186783\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.033683\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.024439\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.114156\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.141993\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.097093\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.156592\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.079116\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.074046\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.060784\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.079571\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.067481\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.109456\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7622, Accuracy: 2025/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.8100000023841858\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8053, Accuracy: 1996/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.7983999848365784\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.204681\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.051464\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.092559\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.165844\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.036309\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.026194\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.095061\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.117331\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.148679\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.102977\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.078059\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.058772\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.075245\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.067426\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.069261\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.064632\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.099091\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.071045\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.013182\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.062929\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8335, Accuracy: 2001/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.8004000186920166\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8409, Accuracy: 1983/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.7932000160217285\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.108129\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.246082\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.175293\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.072780\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.040119\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.252718\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.110196\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.037974\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.072530\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.077978\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.046905\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.117839\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.087144\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.102853\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.075627\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.086335\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.068580\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.054421\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.018408\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.112655\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8886, Accuracy: 1991/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.7964000105857849\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7734, Accuracy: 2035/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.8140000104904175\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.107822\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.071319\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.041790\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.107351\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.055899\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.052657\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.064439\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.043609\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.031671\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.041892\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.061532\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.044044\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.132621\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.045851\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.064188\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.160233\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.127648\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.053753\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.109912\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.047966\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8673, Accuracy: 2018/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.807200014591217\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.8009999990463257\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.08325167093425989\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.8035000115633011\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8128, Accuracy: 2002/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.8008000254631042\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.142876\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.136283\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.156823\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.149175\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.055002\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.223282\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.056125\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.094295\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.088578\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.042924\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.085177\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.111036\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.012455\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.012903\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.085938\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.078864\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.052876\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.095907\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.071418\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.133887\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8024, Accuracy: 2020/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.8080000281333923\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8870, Accuracy: 1991/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.7964000105857849\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.060748\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.090380\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.078722\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.148323\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.066254\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.155159\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.071114\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.115133\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.139246\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.057539\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.029961\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.079341\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.072772\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.026519\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.040318\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.101256\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.104485\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.183630\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.118828\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.030042\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.9367, Accuracy: 1994/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.7975999712944031\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.9099, Accuracy: 1968/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.7871999740600586\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.092447\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.030820\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.078623\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.189337\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.086110\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.094881\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.108234\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.145859\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.130916\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.038841\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.231232\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.130813\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.096590\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.056724\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.050209\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.067540\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.057302\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.062196\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.057531\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.086600\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8983, Accuracy: 1979/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.7915999889373779\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8673, Accuracy: 2018/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.807200014591217\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.053274\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.075721\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.052013\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.045641\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.143464\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.048406\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.072929\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.143873\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.189911\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.214858\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.083822\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.053147\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.060709\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.105545\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.091721\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.062162\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.037579\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.038631\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.018179\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.060487\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8767, Accuracy: 2023/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.8091999888420105\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.7979000061750412\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.0777541403658688\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.801599994301796\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling end\n",
      "\u001b[94m\u001b[30mThis is the end of the flow\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0mSaving data artifacts for end\n",
      "Saved data artifacts for end\n"
     ]
    }
   ],
   "source": [
    "model = model\n",
    "learning_rate = 1e-3\n",
    "best_model = None\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "flflow = FederatedFlow(model, optimizer, rounds=10, checkpoint=True)\n",
    "flflow.runtime = local_runtime\n",
    "flflow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc503676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of the final model weights: tensor([[[ 0.2834,  0.2117, -0.0324],\n",
      "         [ 0.0095, -0.0886, -0.1821],\n",
      "         [-0.0408, -0.2443, -0.0562]],\n",
      "\n",
      "        [[ 0.0860,  0.0590,  0.1691],\n",
      "         [ 0.1381, -0.1127, -0.1722],\n",
      "         [-0.0718, -0.0972, -0.0404]],\n",
      "\n",
      "        [[ 0.0183, -0.0902, -0.1950],\n",
      "         [ 0.1378, -0.1018,  0.1001],\n",
      "         [ 0.0984,  0.0233, -0.0203]]], device='mps:0')\n",
      "\n",
      "Final aggregated model accuracy for 10 rounds of training:         0.7979000061750412\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f'Sample of the final model weights: {flflow.model.state_dict()[\"conv1.weight\"][0]}'\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\nFinal aggregated model accuracy for {flflow.rounds} rounds of training: \\\n",
    "        {flflow.aggregated_model_accuracy}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-python3-11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
