{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8492bb64",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>\n",
    "\n",
    "- [Importation des bibliothèques](#toc1_)\n",
    "  - [Importation des paquets ou modules de la bibliothèque OpenFL](#toc1_1_)\n",
    "  - [Importation des paquets ou modules de la bibliothèque PyTorch](#toc1_2_)\n",
    "  - [Importation d’autres paquets ou modules requis](#toc1_3_)\n",
    "- [Définition du modèle d‘entraînement](#toc2_)\n",
    "  - [Définition des chargeurs de données](#toc2_1_)\n",
    "  - [Téléchargement du modèle de réseau CNN prédéfini](#toc2_2_)\n",
    "  - [Définition de la fonction d'inférence utilisée dans le test](#toc2_3_)\n",
    "- [Définition des règles de l'apprentissage fédéré](#toc3_)\n",
    "  - [Méthode de calcul de la moyenne des poids d'apprentissage fédéré](#toc3_1_)\n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6017fe",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Importation des bibliothèques](#toc0_)\n",
    "\n",
    "## <a id='toc1_1_'></a>[Importation des paquets ou modules de la bibliothèque OpenFL](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f63aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.experimental.workflow.interface import Aggregator, Collaborator, FLSpec\n",
    "from openfl.experimental.workflow.placement import aggregator, collaborator\n",
    "from openfl.experimental.workflow.runtime import LocalRuntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6e4731",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Importation des paquets ou modules de la bibliothèque PyTorch](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b89c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42f022",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Importation d’autres paquets ou modules requis](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d76255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from termcolor import cprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b634c6",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Définition du modèle d‘entraînement](#toc0_)\n",
    "\n",
    "## <a id='toc2_1_'></a>[Définition des chargeurs de données](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2aaf920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32, 50000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/tmp/files/\"\n",
    "\n",
    "tensor_cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "tensor_images = torch.stack([tensor_image for tensor_image, _ in tensor_cifar10], dim=3)\n",
    "\n",
    "tensor_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1a07f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4914, 0.4822, 0.4465])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_mean = tensor_images.view(3, -1).mean(dim=1)\n",
    "tensor_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a726a54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2470, 0.2435, 0.2616])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_std = tensor_images.view(3, -1).std(dim=1)\n",
    "tensor_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ffab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(tensor_mean, tensor_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(tensor_mean, tensor_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(\n",
    "    \"/tmp/files/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_train,\n",
    ")\n",
    "\n",
    "cifar10_test = datasets.CIFAR10(\n",
    "    \"/tmp/files/\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f439e5d",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Téléchargement du modèle de réseau CNN prédéfini](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed9fc735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps:0\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01738796",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18()\n",
    "model.conv1 = nn.Conv2d(\n",
    "    3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
    ")\n",
    "model.fc = nn.Linear(in_features=512, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7045df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
      "            Conv2d-5           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 16, 16]             128\n",
      "              ReLU-7           [-1, 64, 16, 16]               0\n",
      "            Conv2d-8           [-1, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
      "             ReLU-10           [-1, 64, 16, 16]               0\n",
      "       BasicBlock-11           [-1, 64, 16, 16]               0\n",
      "           Conv2d-12           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 16, 16]             128\n",
      "             ReLU-14           [-1, 64, 16, 16]               0\n",
      "           Conv2d-15           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 16, 16]             128\n",
      "             ReLU-17           [-1, 64, 16, 16]               0\n",
      "       BasicBlock-18           [-1, 64, 16, 16]               0\n",
      "           Conv2d-19            [-1, 128, 8, 8]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 8, 8]             256\n",
      "             ReLU-21            [-1, 128, 8, 8]               0\n",
      "           Conv2d-22            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 8, 8]             256\n",
      "           Conv2d-24            [-1, 128, 8, 8]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 8, 8]             256\n",
      "             ReLU-26            [-1, 128, 8, 8]               0\n",
      "       BasicBlock-27            [-1, 128, 8, 8]               0\n",
      "           Conv2d-28            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 8, 8]             256\n",
      "             ReLU-30            [-1, 128, 8, 8]               0\n",
      "           Conv2d-31            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 8, 8]             256\n",
      "             ReLU-33            [-1, 128, 8, 8]               0\n",
      "       BasicBlock-34            [-1, 128, 8, 8]               0\n",
      "           Conv2d-35            [-1, 256, 4, 4]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 4, 4]             512\n",
      "             ReLU-37            [-1, 256, 4, 4]               0\n",
      "           Conv2d-38            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 4, 4]             512\n",
      "           Conv2d-40            [-1, 256, 4, 4]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 4, 4]             512\n",
      "             ReLU-42            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-43            [-1, 256, 4, 4]               0\n",
      "           Conv2d-44            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 4, 4]             512\n",
      "             ReLU-46            [-1, 256, 4, 4]               0\n",
      "           Conv2d-47            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 4, 4]             512\n",
      "             ReLU-49            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-50            [-1, 256, 4, 4]               0\n",
      "           Conv2d-51            [-1, 512, 2, 2]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-53            [-1, 512, 2, 2]               0\n",
      "           Conv2d-54            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 2, 2]           1,024\n",
      "           Conv2d-56            [-1, 512, 2, 2]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-58            [-1, 512, 2, 2]               0\n",
      "       BasicBlock-59            [-1, 512, 2, 2]               0\n",
      "           Conv2d-60            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-62            [-1, 512, 2, 2]               0\n",
      "           Conv2d-63            [-1, 512, 2, 2]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-65            [-1, 512, 2, 2]               0\n",
      "       BasicBlock-66            [-1, 512, 2, 2]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,173,962\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.13\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 47.77\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, next(iter(cifar10_test))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7933b052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m  conv1.weight ............................................. 1728  \u001b[0m\n",
      "\u001b[35m  bn1.weight ................................................. 64  \u001b[0m\n",
      "\u001b[35m  bn1.bias ................................................... 64  \u001b[0m\n",
      "\u001b[35m  layer1.0.conv1.weight ................................... 36864  \u001b[0m\n",
      "\u001b[35m  layer1.0.bn1.weight ........................................ 64  \u001b[0m\n",
      "\u001b[35m  layer1.0.bn1.bias .......................................... 64  \u001b[0m\n",
      "\u001b[35m  layer1.0.conv2.weight ................................... 36864  \u001b[0m\n",
      "\u001b[35m  layer1.0.bn2.weight ........................................ 64  \u001b[0m\n",
      "\u001b[35m  layer1.0.bn2.bias .......................................... 64  \u001b[0m\n",
      "\u001b[35m  layer1.1.conv1.weight ................................... 36864  \u001b[0m\n",
      "\u001b[35m  layer1.1.bn1.weight ........................................ 64  \u001b[0m\n",
      "\u001b[35m  layer1.1.bn1.bias .......................................... 64  \u001b[0m\n",
      "\u001b[35m  layer1.1.conv2.weight ................................... 36864  \u001b[0m\n",
      "\u001b[35m  layer1.1.bn2.weight ........................................ 64  \u001b[0m\n",
      "\u001b[35m  layer1.1.bn2.bias .......................................... 64  \u001b[0m\n",
      "\u001b[35m  layer2.0.conv1.weight ................................... 73728  \u001b[0m\n",
      "\u001b[35m  layer2.0.bn1.weight ....................................... 128  \u001b[0m\n",
      "\u001b[35m  layer2.0.bn1.bias ......................................... 128  \u001b[0m\n",
      "\u001b[35m  layer2.0.conv2.weight .................................. 147456  \u001b[0m\n",
      "\u001b[35m  layer2.0.bn2.weight ....................................... 128  \u001b[0m\n",
      "\u001b[35m  layer2.0.bn2.bias ......................................... 128  \u001b[0m\n",
      "\u001b[35m  layer2.0.downsample.0.weight ............................. 8192  \u001b[0m\n",
      "\u001b[35m  layer2.0.downsample.1.weight .............................. 128  \u001b[0m\n",
      "\u001b[35m  layer2.0.downsample.1.bias ................................ 128  \u001b[0m\n",
      "\u001b[35m  layer2.1.conv1.weight .................................. 147456  \u001b[0m\n",
      "\u001b[35m  layer2.1.bn1.weight ....................................... 128  \u001b[0m\n",
      "\u001b[35m  layer2.1.bn1.bias ......................................... 128  \u001b[0m\n",
      "\u001b[35m  layer2.1.conv2.weight .................................. 147456  \u001b[0m\n",
      "\u001b[35m  layer2.1.bn2.weight ....................................... 128  \u001b[0m\n",
      "\u001b[35m  layer2.1.bn2.bias ......................................... 128  \u001b[0m\n",
      "\u001b[35m  layer3.0.conv1.weight .................................. 294912  \u001b[0m\n",
      "\u001b[35m  layer3.0.bn1.weight ....................................... 256  \u001b[0m\n",
      "\u001b[35m  layer3.0.bn1.bias ......................................... 256  \u001b[0m\n",
      "\u001b[35m  layer3.0.conv2.weight .................................. 589824  \u001b[0m\n",
      "\u001b[35m  layer3.0.bn2.weight ....................................... 256  \u001b[0m\n",
      "\u001b[35m  layer3.0.bn2.bias ......................................... 256  \u001b[0m\n",
      "\u001b[35m  layer3.0.downsample.0.weight ............................ 32768  \u001b[0m\n",
      "\u001b[35m  layer3.0.downsample.1.weight .............................. 256  \u001b[0m\n",
      "\u001b[35m  layer3.0.downsample.1.bias ................................ 256  \u001b[0m\n",
      "\u001b[35m  layer3.1.conv1.weight .................................. 589824  \u001b[0m\n",
      "\u001b[35m  layer3.1.bn1.weight ....................................... 256  \u001b[0m\n",
      "\u001b[35m  layer3.1.bn1.bias ......................................... 256  \u001b[0m\n",
      "\u001b[35m  layer3.1.conv2.weight .................................. 589824  \u001b[0m\n",
      "\u001b[35m  layer3.1.bn2.weight ....................................... 256  \u001b[0m\n",
      "\u001b[35m  layer3.1.bn2.bias ......................................... 256  \u001b[0m\n",
      "\u001b[35m  layer4.0.conv1.weight ................................. 1179648  \u001b[0m\n",
      "\u001b[35m  layer4.0.bn1.weight ....................................... 512  \u001b[0m\n",
      "\u001b[35m  layer4.0.bn1.bias ......................................... 512  \u001b[0m\n",
      "\u001b[35m  layer4.0.conv2.weight ................................. 2359296  \u001b[0m\n",
      "\u001b[35m  layer4.0.bn2.weight ....................................... 512  \u001b[0m\n",
      "\u001b[35m  layer4.0.bn2.bias ......................................... 512  \u001b[0m\n",
      "\u001b[35m  layer4.0.downsample.0.weight ........................... 131072  \u001b[0m\n",
      "\u001b[35m  layer4.0.downsample.1.weight .............................. 512  \u001b[0m\n",
      "\u001b[35m  layer4.0.downsample.1.bias ................................ 512  \u001b[0m\n",
      "\u001b[35m  layer4.1.conv1.weight ................................. 2359296  \u001b[0m\n",
      "\u001b[35m  layer4.1.bn1.weight ....................................... 512  \u001b[0m\n",
      "\u001b[35m  layer4.1.bn1.bias ......................................... 512  \u001b[0m\n",
      "\u001b[35m  layer4.1.conv2.weight ................................. 2359296  \u001b[0m\n",
      "\u001b[35m  layer4.1.bn2.weight ....................................... 512  \u001b[0m\n",
      "\u001b[35m  layer4.1.bn2.bias ......................................... 512  \u001b[0m\n",
      "\u001b[35m  fc.weight ................................................ 5120  \u001b[0m\n",
      "\u001b[35m  fc.bias .................................................... 10  \u001b[0m\n",
      "\u001b[35m _________________________________________________________________ \u001b[0m\n",
      "\u001b[35m  total parameters ..................................... 11173962  \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    length = 67\n",
    "    names = [n for (n, p) in model.named_parameters() if p.requires_grad]\n",
    "    name = \"total parameters\"\n",
    "    names.append(name)\n",
    "    max_length = max(map(len, names))\n",
    "    formatted_names = [f\"{f'  {n} ':.<{max_length + 3}}\" for n in names]\n",
    "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    params.append(sum(params))\n",
    "    formatted_params = [f\"{f' {p}  ':.>{length - max_length - 3}}\" for p in params]\n",
    "\n",
    "    for n, p in zip(formatted_names[:-1], formatted_params[:-1]):\n",
    "        cprint((n + p), \"magenta\")\n",
    "    cprint(\" \" + \"_\" * (length - 2) + \" \", \"magenta\")\n",
    "    cprint(\n",
    "        (formatted_names[-1] + formatted_params[-1]),\n",
    "        \"magenta\",\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "\n",
    "    return names, params\n",
    "\n",
    "\n",
    "names, params = count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9993220e",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[Définition de la fonction d'inférence utilisée dans le test](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13b360d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(network, test_loader):\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = network(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction=\"sum\").item()\n",
    "            pred = output.data.max(dim=1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    cprint(\n",
    "        \"Test set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\".format(\n",
    "            test_loss,\n",
    "            correct,\n",
    "            len(test_loader.dataset),\n",
    "            100.0 * correct / len(test_loader.dataset),\n",
    "        ),\n",
    "        \"magenta\",\n",
    "        attrs=[\"underline\"],\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "    return float(correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f8c156a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[35mTest set: Avg. loss: 2.5267, Accuracy: 951/10000 (10%)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09510000050067902"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(cifar10_test, batch_size=500, shuffle=False)\n",
    "\n",
    "inference(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1dabb0",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Définition des règles de l'apprentissage fédéré](#toc0_)\n",
    "\n",
    "## <a id='toc3_1_'></a>[Méthode de calcul de la moyenne des poids d'apprentissage fédéré](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59d93477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedAvg(models, weights=None):\n",
    "    new_model = models[0]\n",
    "    state_dicts = [model.state_dict() for model in models]\n",
    "    state_dict = new_model.state_dict()\n",
    "    for key in models[1].state_dict():\n",
    "        if state_dict[key].dim() != 0:\n",
    "            state_dict[key] = torch.from_numpy(\n",
    "                np.average(\n",
    "                    [state[key].cpu().numpy() for state in state_dicts],\n",
    "                    axis=0,\n",
    "                    weights=weights,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            state_dict[key] = torch.from_numpy(\n",
    "                np.average(\n",
    "                    [state[key].reshape(1).cpu().numpy() for state in state_dicts],\n",
    "                    axis=0,\n",
    "                    weights=weights,\n",
    "                )\n",
    "            )\n",
    "    new_model.load_state_dict(state_dict)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3d20ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregator step \"start\" registered\n",
      "Collaborator step \"aggregated_model_validation\" registered\n",
      "Collaborator step \"train\" registered\n",
      "Collaborator step \"local_model_validation\" registered\n",
      "Aggregator step \"join\" registered\n",
      "Aggregator step \"end\" registered\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "log_interval = 10\n",
    "momentum = 0.5\n",
    "\n",
    "\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "\n",
    "class FederatedFlow(FLSpec):\n",
    "\n",
    "    def __init__(self, model=None, optimizer=None, rounds=3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Importe un modèle personnalisé et ajoute le bon algorithme d’optimisation pour ce dernier.\n",
    "        if model is not None:\n",
    "            self.model = model\n",
    "            self.optimizer = optimizer\n",
    "        # Chargez le modèle `Net()` et configurez l'optimiseur pour qu'il s'applique uniquement à ce\n",
    "        # modèle.\n",
    "        else:\n",
    "            self.model = Net()\n",
    "            self.optimizer = optim.SGD(\n",
    "                self.model.parameters(), lr=learning_rate, momentum=momentum\n",
    "            )\n",
    "        self.rounds = rounds\n",
    "\n",
    "    # Un agrégateur est le nœud central de l'apprentissage fédéré.\n",
    "\n",
    "    # L'agrégateur commence par un modèle et un optimiseur transmis de manière facultative.\n",
    "\n",
    "    # L'agrégateur commence le flux avec la tâche de `start`, où la liste des collaborateurs est\n",
    "    # extraite de l'exécution (`self.collaborators = self.runtime.collaborators`) et est ensuite\n",
    "    # utilisée comme liste de participants pour exécuterla tâche énumérée dans `self.next`,\n",
    "    # `aggregated_model_validation`.\n",
    "    @aggregator\n",
    "    def start(self):\n",
    "        cprint(\"Performing initialization for model\", \"black\", attrs=[\"bold\"])\n",
    "        self.collaborators = self.runtime.collaborators\n",
    "        self.private = 10\n",
    "        self.current_round = 0\n",
    "        self.next(\n",
    "            self.aggregated_model_validation,\n",
    "            foreach=\"collaborators\",\n",
    "            exclude=[\"private\"],\n",
    "        )\n",
    "\n",
    "    # Le modèle, l'optimiseur et tout ce qui n'est pas explicitement exclu de la fonction suivante\n",
    "    # seront transmis de la fonction de `start` de l'agrégateur à la tâche\n",
    "    # `aggregated_model_validation` du collaborateur.\n",
    "\n",
    "    # L’endroit où les tâches sont exécutées est déterminé par le décorateur de placement qui\n",
    "    # précède chaque définition de tâche (`@aggregator` ou `@collaborator`).\n",
    "\n",
    "    # Une fois que chaque collaborateur (défini dans l’exécution) a terminé la tâche\n",
    "    # `aggregated_model_validation`, il transmet son état actuel à la tâche `train`, de `train` à\n",
    "    # `local_model_validation`, et enfin à `join` à l'agrégateur.\n",
    "\n",
    "    # C'est au niveau de `join` qu'une moyenne des poids des modèles est calculée et que le tour\n",
    "    # suivant peut commencer.\n",
    "    @collaborator\n",
    "    def aggregated_model_validation(self):\n",
    "        cprint(\n",
    "            f\"Performing aggregated model validation for collaborator {self.input}\",\n",
    "            \"red\",\n",
    "            attrs=[\"bold\"],\n",
    "        )\n",
    "        self.agg_validation_score = inference(self.model, self.test_loader)\n",
    "        cprint(\n",
    "            f\"{self.input} value of {self.agg_validation_score}\",\n",
    "            \"red\",\n",
    "            attrs=[\"underline\"],\n",
    "        )\n",
    "        self.next(self.train)\n",
    "\n",
    "    @collaborator\n",
    "    def train(self):\n",
    "        if model is not None:\n",
    "            self.model = model\n",
    "            self.optimizer = optimizer\n",
    "        else:\n",
    "            self.model = Net()\n",
    "            self.optimizer = optim.SGD(\n",
    "                self.model.parameters(), lr=learning_rate, momentum=momentum\n",
    "            )\n",
    "        self.model.train()\n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                cprint(\n",
    "                    \"Train Epoch: 1 [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                        batch_idx * len(data),\n",
    "                        len(self.train_loader.dataset),\n",
    "                        100.0 * batch_idx / len(self.train_loader),\n",
    "                        loss.item(),\n",
    "                    ),\n",
    "                    \"yellow\",\n",
    "                )\n",
    "                self.loss = loss.item()\n",
    "                torch.save(self.model.state_dict(), \"model.pth\")\n",
    "                torch.save(self.optimizer.state_dict(), \"optimizer.pth\")\n",
    "        self.training_completed = True\n",
    "        self.next(self.local_model_validation)\n",
    "\n",
    "    @collaborator\n",
    "    def local_model_validation(self):\n",
    "        self.local_validation_score = inference(self.model, self.test_loader)\n",
    "        cprint(\n",
    "            f\"Doing local model validation for collaborator {self.input}: \\\n",
    "                {self.local_validation_score}\",\n",
    "            \"white\",\n",
    "        )\n",
    "        self.next(self.join, exclude=[\"training_completed\"])\n",
    "\n",
    "    @aggregator\n",
    "    def join(self, inputs):\n",
    "        self.average_loss = sum(input.loss for input in inputs) / len(inputs)\n",
    "        self.aggregated_model_accuracy = sum(\n",
    "            input.agg_validation_score for input in inputs\n",
    "        ) / len(inputs)\n",
    "        self.local_model_accuracy = sum(\n",
    "            input.local_validation_score for input in inputs\n",
    "        ) / len(inputs)\n",
    "        cprint(\n",
    "            f\"Average aggregated model validation values = \\\n",
    "                {self.aggregated_model_accuracy}\",\n",
    "            \"green\",\n",
    "        )\n",
    "        cprint(f\"Average training loss = {self.average_loss}\", \"green\")\n",
    "        cprint(\n",
    "            f\"Average local model validation values = \\\n",
    "            {self.local_model_accuracy}\",\n",
    "            \"green\",\n",
    "        )\n",
    "        self.model = FedAvg([input.model for input in inputs])\n",
    "        self.optimizer = [input.optimizer for input in inputs][0]\n",
    "        self.current_round += 1\n",
    "        if self.current_round < self.rounds:\n",
    "            self.next(\n",
    "                self.aggregated_model_validation,\n",
    "                foreach=\"collaborators\",\n",
    "                exclude=[\"private\"],\n",
    "            )\n",
    "        else:\n",
    "            self.next(self.end)\n",
    "\n",
    "    @aggregator\n",
    "    def end(self):\n",
    "        cprint(\"This is the end of the flow\", \"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b96e3045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local runtime collaborators = ['Portland', 'Seattle', 'Chandler', 'Bangalore']\n"
     ]
    }
   ],
   "source": [
    "batch_size_train = 64\n",
    "\n",
    "# Setup participants\n",
    "aggregator = Aggregator()\n",
    "aggregator.private_attributes = {}\n",
    "\n",
    "# Setup collaborators with private attributes\n",
    "collaborator_names = [\"Portland\", \"Seattle\", \"Chandler\", \"Bangalore\"]\n",
    "collaborators = [Collaborator(name=name) for name in collaborator_names]\n",
    "for idx, collaborator in enumerate(collaborators):\n",
    "    local_train = deepcopy(cifar10_train)\n",
    "    local_test = deepcopy(cifar10_test)\n",
    "    local_train.data = cifar10_train.data[idx :: len(collaborators)]\n",
    "    local_train.targets = cifar10_train.targets[idx :: len(collaborators)]\n",
    "    local_test.data = cifar10_test.data[idx :: len(collaborators)]\n",
    "    local_test.targets = cifar10_test.targets[idx :: len(collaborators)]\n",
    "    collaborator.private_attributes = {\n",
    "        \"train_loader\": DataLoader(\n",
    "            local_train, batch_size=batch_size_train, shuffle=True\n",
    "        ),\n",
    "        \"test_loader\": DataLoader(\n",
    "            local_test, batch_size=batch_size_train, shuffle=True\n",
    "        ),\n",
    "    }\n",
    "\n",
    "local_runtime = LocalRuntime(\n",
    "    aggregator=aggregator, collaborators=collaborators, backend=\"single_process\"\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Local runtime collaborators = {local_runtime.collaborators}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5494deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.environ.get(\"USERNAME\") is None:\n",
    "    os.environ[\"USERNAME\"] = \"Hao\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8018e1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haozhang\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "print(getpass.getuser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edbaff16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created flow FederatedFlow\n",
      "\n",
      "Calling start\n",
      "\u001b[94m\u001b[1m\u001b[30mPerforming initialization for model\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for start\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for start\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 2.5189, Accuracy: 243/2500 (10%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.09719999879598618\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 2.507246\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 2.055416\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 1.996434\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 1.759570\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 1.840103\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 1.821962\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 1.779120\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 1.559868\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 1.576398\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 1.568259\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 1.514736\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 1.664685\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 1.600420\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 1.591690\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 1.419441\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 1.425927\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 1.413613\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 1.444169\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 1.355883\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 1.688315\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 1.4528, Accuracy: 1206/2500 (48%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.48240000009536743\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 2.5216, Accuracy: 231/2500 (9%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.09239999949932098\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 1.568311\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 1.540344\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 1.685527\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 1.359889\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 1.432827\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 1.551057\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 1.626611\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 1.227588\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 1.512059\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 1.283453\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 1.348265\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 1.350985\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 1.275960\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 1.277928\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 1.372214\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 1.175751\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 1.611180\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 1.297863\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 1.707036\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 1.253155\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 1.2713, Accuracy: 1325/2500 (53%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.5299999713897705\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 2.5176, Accuracy: 249/2500 (10%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.09960000216960907\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 1.211295\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 1.359396\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 1.610191\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 1.235403\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 1.054963\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 1.567775\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 1.201848\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 1.380748\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 1.128841\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 1.217734\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 1.313064\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 1.213237\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 1.047824\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 1.089371\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 1.301605\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 1.311100\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 1.125348\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 1.294961\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 1.353907\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 1.234286\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 1.2215, Accuracy: 1359/2500 (54%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.5436000227928162\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 2.5488, Accuracy: 228/2500 (9%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.09120000153779984\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 1.353196\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 1.118306\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 1.234874\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 1.143464\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 1.413663\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 1.103479\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 1.030663\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 1.186144\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 1.004862\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 1.214293\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 1.411936\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 1.212347\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 1.158431\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 1.389857\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 1.177079\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 1.308084\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.909296\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 1.097289\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 1.112613\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 1.275905\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 1.0370, Accuracy: 1599/2500 (64%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.6395999789237976\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.09510000050067902\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 1.3629152178764343\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.5488999933004379\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 1.0382, Accuracy: 1592/2500 (64%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.6367999911308289\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 1.086797\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 1.344097\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 1.052621\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 1.224665\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 1.134176\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 1.160086\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 1.046264\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.982295\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 1.135717\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 1.057793\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 1.089164\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.822049\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.985883\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 1.150930\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.954645\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.921855\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 1.372328\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 1.125590\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 1.109178\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 1.209094\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 1.0755, Accuracy: 1594/2500 (64%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.6376000046730042\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 1.0517, Accuracy: 1582/2500 (63%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.6327999830245972\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 1.139675\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.886950\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.971429\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.782329\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 1.327921\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.968783\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.864196\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.983403\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.942231\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.899182\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.856795\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 1.086936\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.909509\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 1.058819\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 1.024536\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.940757\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.912857\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 1.122212\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 1.160462\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.892109\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8810, Accuracy: 1722/2500 (69%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.6887999773025513\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 1.0689, Accuracy: 1545/2500 (62%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.6179999709129333\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.970715\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.959872\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 1.112757\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.863095\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 1.030093\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 1.038746\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 1.010695\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.876217\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 1.000112\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.898559\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.855094\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 1.170483\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 1.090236\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 1.036980\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.839767\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 1.116517\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.835413\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.639218\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.984539\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.785589\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8656, Accuracy: 1728/2500 (69%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.6912000179290771\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 1.0370, Accuracy: 1599/2500 (64%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.6395999789237976\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.962108\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.797652\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.807634\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 1.111158\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.885035\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 1.064903\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.920865\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.548344\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 1.057180\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.832027\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 1.334215\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.715924\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 1.155120\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 1.187140\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 1.087356\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.937171\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.861623\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.994949\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.806784\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.982126\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7927, Accuracy: 1805/2500 (72%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.722000002861023\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.6317999809980392\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.9672292321920395\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.6849000006914139\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8291, Accuracy: 1800/2500 (72%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.7200000286102295\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.845655\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.886510\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.920088\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.957818\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.860599\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.847463\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.807718\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 1.021508\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.999043\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.970025\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.851210\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.765157\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.954328\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.818623\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.679940\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 1.034837\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.590439\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.873417\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.896660\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.773030\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7555, Accuracy: 1847/2500 (74%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.7387999892234802\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8415, Accuracy: 1754/2500 (70%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.7016000151634216\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.977894\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.832731\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.784971\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.904907\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.809732\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.890707\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.587847\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.876180\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 1.039667\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.884435\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.917722\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.757563\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.507548\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 1.027674\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.953868\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.743684\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.876239\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.884882\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.917751\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.844656\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7776, Accuracy: 1801/2500 (72%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.7203999757766724\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.8382, Accuracy: 1753/2500 (70%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.701200008392334\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.758256\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.840605\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.921668\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.755164\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.908872\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.826267\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.816591\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.626227\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 1.029942\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.717263\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 1.092506\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.630927\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.693567\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.858085\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.801787\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.975228\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.898077\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.883653\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.996763\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.662476\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7501, Accuracy: 1846/2500 (74%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.7383999824523926\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7927, Accuracy: 1805/2500 (72%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.722000002861023\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.863181\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 1.128267\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.885320\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.881662\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.724080\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.799673\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.834873\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.704116\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.602827\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.994779\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.882596\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.648582\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.471485\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.809266\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.758317\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.730312\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.682582\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.632530\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.877475\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.832845\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6971, Accuracy: 1903/2500 (76%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.7612000107765198\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.711200013756752\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.7782518565654755\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.7396999895572662\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7226, Accuracy: 1872/2500 (75%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.7487999796867371\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.890358\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.890699\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.713475\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.883044\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.786750\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 1.062031\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.819571\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 1.008945\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.781945\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.739602\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.737795\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.789514\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.998452\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.614642\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.606580\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.726666\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.668494\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.628454\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.815968\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.797721\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6657, Accuracy: 1927/2500 (77%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.770799994468689\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7164, Accuracy: 1875/2500 (75%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.75\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.707203\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.617095\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.758699\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.620640\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.805722\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.812398\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.615263\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.953133\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.734257\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.633209\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.626726\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.791617\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.630719\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.656672\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.711704\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.769108\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 1.127869\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.665532\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.698677\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.723007\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6888, Accuracy: 1891/2500 (76%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.7563999891281128\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7286, Accuracy: 1851/2500 (74%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.7404000163078308\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.656002\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.782585\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.740469\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.869606\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.698624\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.537320\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.799442\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.622195\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.683113\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.916203\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.785497\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.841183\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.575755\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.644073\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.768944\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.700113\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.645809\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.604712\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.571558\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.891842\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7564, Accuracy: 1827/2500 (73%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.7307999730110168\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6971, Accuracy: 1903/2500 (76%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.7612000107765198\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.600622\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.738607\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.664463\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.522570\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.699037\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.823238\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.774045\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.738065\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.606850\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.651800\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.441936\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.732744\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 1.009674\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.839437\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.871403\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.864864\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.907345\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.673530\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.919397\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.657176\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6476, Accuracy: 1955/2500 (78%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.7820000052452087\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.7501000016927719\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.7674364745616913\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.7599999904632568\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6478, Accuracy: 1952/2500 (78%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.7807999849319458\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.577691\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.891881\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.712064\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.525262\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.636647\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.487571\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.585618\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.703531\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.710135\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.614675\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.634085\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.563731\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.742917\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.679851\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.941411\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.530589\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.773708\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.453541\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.767015\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.456606\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6137, Accuracy: 1986/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.7943999767303467\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6355, Accuracy: 1944/2500 (78%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.7775999903678894\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.906771\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.802266\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.607837\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.685442\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.976542\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.560357\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.602792\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.724878\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.870353\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.572215\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.662838\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.555503\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.788016\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.703198\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.834353\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.700383\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.536506\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.643410\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.639879\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.717907\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6807, Accuracy: 1929/2500 (77%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.7716000080108643\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6519, Accuracy: 1936/2500 (77%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.774399995803833\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.575281\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.393320\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.390581\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.815625\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.755605\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.510936\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.606902\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.583184\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.832979\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.686109\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.756571\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.805807\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.739703\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.722827\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.709294\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.649654\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.617631\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.733210\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.543986\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.832104\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6010, Accuracy: 1983/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.7932000160217285\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6476, Accuracy: 1955/2500 (78%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.7820000052452087\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.702410\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.613338\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.841387\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.686893\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.452654\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.776042\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.769608\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.708662\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.608212\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.591252\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.676481\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.659068\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.762721\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.555432\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.826747\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.498836\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.585442\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.539205\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.545013\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.636834\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7048, Accuracy: 1925/2500 (77%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.7699999809265137\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.7786999940872192\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.6608626842498779\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.7822999954223633\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6802, Accuracy: 1935/2500 (77%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.7739999890327454\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.811476\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.726395\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.572249\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.589459\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.609804\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.728355\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.648356\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.687555\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.803164\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.622330\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.665812\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.463214\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.794155\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.743860\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.549433\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.654571\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.608831\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.736117\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.456538\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.762893\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5983, Accuracy: 2022/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.8087999820709229\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7017, Accuracy: 1931/2500 (77%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.7724000215530396\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.736793\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.454640\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.878621\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.793967\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.599656\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.440996\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.456643\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.765688\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.495006\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.377255\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.680961\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.631692\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.511312\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.440412\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.798844\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.538174\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.656307\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.726265\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.605479\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.606249\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5809, Accuracy: 2015/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.8059999942779541\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7252, Accuracy: 1903/2500 (76%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.7612000107765198\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.439788\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.570614\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.516488\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.706201\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.467964\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.548712\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.759425\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.532677\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.724384\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.578477\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.588485\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.700214\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.627436\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.333727\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.725815\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.390108\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.702828\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.872812\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.568021\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.706055\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5975, Accuracy: 1981/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.7924000024795532\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.7048, Accuracy: 1925/2500 (77%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.7699999809265137\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.415658\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.747908\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.419376\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.437587\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.459899\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.715195\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.543969\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.461068\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.909604\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.581315\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.773959\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.501084\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.545194\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.452055\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.672691\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.622167\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.577895\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.833263\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.917484\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.619062\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5609, Accuracy: 2023/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.8091999888420105\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.7694000005722046\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.6735647022724152\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.8040999919176102\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5835, Accuracy: 2010/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.8040000200271606\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.559930\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.700353\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.539508\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.533386\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.510888\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.634274\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.548772\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.685464\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.504827\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.722652\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.630982\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 1.018660\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.901278\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.585519\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.364331\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.615870\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.641543\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.494245\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.497032\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.598772\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5825, Accuracy: 2004/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.8015999794006348\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5813, Accuracy: 1988/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.795199990272522\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.659975\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.464142\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.461361\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.449715\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.682779\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.802511\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.623917\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.544735\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.897691\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.728468\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.579880\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.425406\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.709606\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.758044\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.631824\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.549425\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.416809\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.459042\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.472255\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.563027\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5845, Accuracy: 2007/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.8027999997138977\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5832, Accuracy: 1985/2500 (79%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.7940000295639038\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.867157\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.562247\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.731483\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.480489\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.464471\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.658411\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.501415\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.382075\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.713532\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.571814\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.305964\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.448770\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.515942\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.523797\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.469682\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.847772\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.648465\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.630891\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.361869\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.785344\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5429, Accuracy: 2039/2500 (82%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.8155999779701233\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5609, Accuracy: 2023/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.8091999888420105\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.561728\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.535071\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.412592\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.577344\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.484273\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.398169\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.539546\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.632467\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.679299\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.573006\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.419470\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.490696\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.526982\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.715994\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.521224\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.621630\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.818777\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.577869\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.658702\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.552548\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5248, Accuracy: 2054/2500 (82%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.8216000199317932\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.8006000071763992\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.6249229162931442\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.8103999942541122\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5242, Accuracy: 2061/2500 (82%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.824400007724762\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.494655\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.590333\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.638023\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.412833\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.387721\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.497566\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.679012\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.602322\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.696760\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.278969\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.456002\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.582869\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.594992\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.559994\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.600229\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.495412\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.426960\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.508680\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.688792\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.424284\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.4999, Accuracy: 2092/2500 (84%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.8367999792098999\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5444, Accuracy: 2024/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.8095999956130981\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.675885\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.625817\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.372511\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.545873\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.620401\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.561609\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.495968\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.570729\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.511117\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.555665\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.418025\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.652361\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.466299\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.535915\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.810985\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.466195\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.636280\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.761082\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.560757\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.463739\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5132, Accuracy: 2048/2500 (82%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.8191999793052673\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5492, Accuracy: 2012/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.8047999739646912\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.561832\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.582774\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.443364\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.428696\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.501096\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.525487\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.482550\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.655128\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.472890\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.625692\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.425635\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.552439\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.336286\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.377126\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.364652\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.549522\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.532217\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.549230\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.356277\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.511776\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5559, Accuracy: 2001/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.8004000186920166\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5248, Accuracy: 2054/2500 (82%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.8216000199317932\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.627300\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.566701\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.378974\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.462498\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.521284\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.500445\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.391875\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.459673\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.371995\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.586958\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.668476\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.563923\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.531031\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.352369\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.395022\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.530325\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.421688\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.464048\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.529769\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.450458\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6089, Accuracy: 2020/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.8080000281333923\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.8150999993085861\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.462564080953598\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.816100001335144\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5998, Accuracy: 2033/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.8131999969482422\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.567673\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.683949\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.468610\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.511852\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.755526\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.499192\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.579221\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.476346\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.553300\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.417934\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.506622\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.456797\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.447989\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.604979\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.406790\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.899857\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.656434\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.504230\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.364224\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.340365\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.4827, Accuracy: 2092/2500 (84%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.8367999792098999\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6077, Accuracy: 2014/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.8055999875068665\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.496879\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.330438\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.504486\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.467307\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.547249\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.388527\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.583134\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.620503\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.582703\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.686200\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.489317\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.546364\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.550652\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.335196\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.297399\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.356727\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.563783\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.515701\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.528973\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.562215\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5178, Accuracy: 2053/2500 (82%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.8212000131607056\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6428, Accuracy: 2000/2500 (80%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.800000011920929\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.485864\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.691942\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.623480\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.501583\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.565511\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.351102\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.445889\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.380268\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.463770\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.345553\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.459477\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.418635\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.409588\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.495149\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.376124\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.509094\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.622585\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.452568\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.531884\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.721534\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5051, Accuracy: 2061/2500 (82%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.824400007724762\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.6089, Accuracy: 2020/2500 (81%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.8080000281333923\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.824179\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.373176\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.682148\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.426239\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.354503\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.769836\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.425271\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.568857\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.537914\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.527458\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.509920\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.407722\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.710645\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.426670\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.461471\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.543558\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.513311\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.576697\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.380741\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.232503\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.4932, Accuracy: 2087/2500 (83%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.8348000049591064\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.8067000061273575\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.4641542211174965\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.8293000012636185\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Portland\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5077, Accuracy: 2069/2500 (83%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mPortland value of 0.8276000022888184\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.660431\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.384467\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.680373\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.529581\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.475592\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.319544\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.387937\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.435685\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.435509\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.348409\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.618984\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.544781\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.626976\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.391621\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.259972\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.397837\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.441202\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.432621\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.408783\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.604392\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5358, Accuracy: 2061/2500 (82%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Portland:                 0.824400007724762\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Seattle\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.4924, Accuracy: 2083/2500 (83%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mSeattle value of 0.8331999778747559\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.463860\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.563348\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.506889\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.666987\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.687726\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.499983\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.491980\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.548710\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.475256\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.565929\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.564988\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.398342\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.809192\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.667469\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.505512\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.665671\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.593042\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.392826\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.411667\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.378233\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.4693, Accuracy: 2116/2500 (85%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Seattle:                 0.8464000225067139\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Chandler\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.5197, Accuracy: 2083/2500 (83%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mChandler value of 0.8331999778747559\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.398435\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.382149\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.389138\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.338234\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.478996\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.648683\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.456014\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.452135\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.629038\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.364325\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.527481\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.310012\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.457488\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.414812\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.602078\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.659404\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.488327\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.562009\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.307650\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.482673\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.4989, Accuracy: 2077/2500 (83%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Chandler:                 0.8307999968528748\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling aggregated_model_validation\n",
      "\u001b[94m\u001b[1m\u001b[31mPerforming aggregated model validation for collaborator Bangalore\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.4932, Accuracy: 2087/2500 (83%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[4m\u001b[31mBangalore value of 0.8348000049591064\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for aggregated_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling train\n",
      "\u001b[94m\u001b[33mTrain Epoch: 1 [0/12500 (0%)]\tLoss: 0.510428\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [640/12500 (5%)]\tLoss: 0.631179\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1280/12500 (10%)]\tLoss: 0.295738\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [1920/12500 (15%)]\tLoss: 0.653827\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [2560/12500 (20%)]\tLoss: 0.665118\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3200/12500 (26%)]\tLoss: 0.272806\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [3840/12500 (31%)]\tLoss: 0.466820\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [4480/12500 (36%)]\tLoss: 0.338275\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5120/12500 (41%)]\tLoss: 0.319080\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [5760/12500 (46%)]\tLoss: 0.430398\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [6400/12500 (51%)]\tLoss: 0.480921\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7040/12500 (56%)]\tLoss: 0.691690\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [7680/12500 (61%)]\tLoss: 0.475686\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8320/12500 (66%)]\tLoss: 0.468979\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [8960/12500 (71%)]\tLoss: 0.475202\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [9600/12500 (77%)]\tLoss: 0.446802\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10240/12500 (82%)]\tLoss: 0.451894\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [10880/12500 (87%)]\tLoss: 0.480571\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [11520/12500 (92%)]\tLoss: 0.421142\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[33mTrain Epoch: 1 [12160/12500 (97%)]\tLoss: 0.219245\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for train\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling local_model_validation\n",
      "\u001b[94m\u001b[4m\u001b[35mTest set: Avg. loss: 0.4902, Accuracy: 2089/2500 (84%)\u001b[0m\u001b[0m\u001b[94m\n",
      "\n",
      "\u001b[0m\u001b[94m\u001b[97mDoing local model validation for collaborator Bangalore:                 0.8356000185012817\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for local_model_validation\u001b[0m\u001b[94m\n",
      "\u001b[0mShould transfer from local_model_validation to join\n",
      "\n",
      "Calling join\n",
      "\u001b[94m\u001b[32mAverage aggregated model validation values =                 0.8321999907493591\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage training loss = 0.4211358204483986\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94m\u001b[32mAverage local model validation values =             0.8343000113964081\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaving data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mSaved data artifacts for join\u001b[0m\u001b[94m\n",
      "\u001b[0m\n",
      "Calling end\n",
      "\u001b[94m\u001b[30mThis is the end of the flow\u001b[0m\u001b[0m\u001b[94m\n",
      "\u001b[0mSaving data artifacts for end\n",
      "Saved data artifacts for end\n"
     ]
    }
   ],
   "source": [
    "model = model\n",
    "learning_rate = 1e-3\n",
    "best_model = None\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "flflow = FederatedFlow(model, optimizer, rounds=10, checkpoint=True)\n",
    "flflow.runtime = local_runtime\n",
    "flflow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc503676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of the final model weights: tensor([[[ 0.1304,  0.1874, -0.0322],\n",
      "         [ 0.1780, -0.1943,  0.1084],\n",
      "         [-0.1219,  0.0603,  0.0384]],\n",
      "\n",
      "        [[-0.0386, -0.1434, -0.1625],\n",
      "         [ 0.0084, -0.2694, -0.0523],\n",
      "         [-0.2608, -0.0260,  0.2018]],\n",
      "\n",
      "        [[ 0.0590,  0.1027, -0.1248],\n",
      "         [-0.0398, -0.2158,  0.0340],\n",
      "         [ 0.0759,  0.0117,  0.2058]]], device='mps:0')\n",
      "\n",
      "Final aggregated model accuracy for 10 rounds of training:         0.8321999907493591\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f'Sample of the final model weights: {flflow.model.state_dict()[\"conv1.weight\"][0]}'\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\nFinal aggregated model accuracy for {flflow.rounds} rounds of training: \\\n",
    "        {flflow.aggregated_model_accuracy}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-python3-11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
